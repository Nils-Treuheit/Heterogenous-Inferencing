{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ai_hardware_accelerators.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Create Simple Tensorflow Models"
      ],
      "metadata": {
        "id": "MDplXLeYwNNy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4ghjtz04EoA-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8986aff1-936b-4d97-fbc5-c20e3b081209"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/relu_act/assets\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpng2qbssg/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/leaky_relu_act/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/leaky_relu_act/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp05kcb43g/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp05kcb43g/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/tanh_act/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/tanh_act/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpe7yc4b8z/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpe7yc4b8z/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/sigmoid_act/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/sigmoid_act/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpj6ikn8_f/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpj6ikn8_f/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/scalar_mult/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/scalar_mult/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp2dwm1hfn/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp2dwm1hfn/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/small_dense/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/small_dense/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpcsh271n4/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpcsh271n4/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/big_dense/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/big_dense/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp0a4hufyc/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp0a4hufyc/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/simple_conv2d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/simple_conv2d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp9an7go59/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp9an7go59/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/dilated_conv2d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/dilated_conv2d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpgffaldm8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpgffaldm8/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/strided_conv2d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/strided_conv2d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpvd9ejo9w/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpvd9ejo9w/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/big_conv2d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/big_conv2d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpemrrzb34/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpemrrzb34/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/small_conv2d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/small_conv2d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp1n56pbr3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp1n56pbr3/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/many_conv2d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/many_conv2d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpylnq9lfz/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpylnq9lfz/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/few_conv2d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/few_conv2d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpv3ji28zu/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpv3ji28zu/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import os, subprocess\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "BatchSize = 512\n",
        "picture_shape = (128,128,3)\n",
        "linear_data_shape = (128)\n",
        "pictures = tf.keras.Input(shape=picture_shape, batch_size=BatchSize)\n",
        "linear_data = tf.keras.Input(shape=linear_data_shape, batch_size=BatchSize)\n",
        "layers,models = ([],[])\n",
        "\n",
        "\n",
        "# relu activation model\n",
        "layers.append(tf.keras.layers.Activation('relu')(linear_data))\n",
        "relu_act = tf.keras.Model(inputs=linear_data,outputs=layers[-1],name=\"relu_act\")\n",
        "models.append(relu_act)\n",
        "\n",
        "# leaky relu activation model\n",
        "layers.append(tf.keras.layers.LeakyReLU()(linear_data))\n",
        "leaky_relu_act = tf.keras.Model(inputs=linear_data,outputs=layers[-1],name=\"leaky_relu_act\")\n",
        "models.append(leaky_relu_act)\n",
        "\n",
        "# tanh activation model\n",
        "layers.append(tf.keras.layers.Activation('tanh')(linear_data))\n",
        "tanh_act = tf.keras.Model(inputs=linear_data,outputs=layers[-1],name=\"tanh_act\")\n",
        "models.append(tanh_act)\n",
        "\n",
        "# sigmoid activation model\n",
        "layers.append(tf.keras.layers.Activation('sigmoid')(linear_data))\n",
        "sigmoid_act = tf.keras.Model(inputs=linear_data,outputs=layers[-1],name=\"sigmoid_act\")\n",
        "models.append(sigmoid_act)\n",
        "\n",
        "# scalar_multiply model\n",
        "layers.append(tf.keras.layers.Lambda(lambda x: x * 5.0)(linear_data))\n",
        "scalar_mult = tf.keras.Model(inputs=linear_data,outputs=layers[-1],name=\"scalar_mult\")\n",
        "models.append(scalar_mult)\n",
        "\n",
        "# small dense model\n",
        "layers.append(tf.keras.layers.Dense(8)(linear_data))\n",
        "small_dense = tf.keras.Model(inputs=linear_data,outputs=layers[-1],name=\"small_dense\")\n",
        "models.append(small_dense)\n",
        "\n",
        "# big dense model\n",
        "layers.append(tf.keras.layers.Dense(512)(linear_data))\n",
        "big_dense = tf.keras.Model(inputs=linear_data,outputs=layers[-1],name=\"big_dense\")\n",
        "models.append(big_dense)\n",
        "\n",
        "# simple conv2d model\n",
        "layers.append(tf.keras.layers.Conv2D(12,3)(pictures))\n",
        "simple_conv2d = tf.keras.Model(inputs=pictures,outputs=layers[-1],name=\"simple_conv2d\")\n",
        "models.append(simple_conv2d)\n",
        "\n",
        "# dilated conv2d model\n",
        "layers.append(tf.keras.layers.Conv2D(12,3,dilation_rate=2)(pictures))\n",
        "dilated_conv2d = tf.keras.Model(inputs=pictures,outputs=layers[-1],name=\"dilated_conv2d\")\n",
        "models.append(dilated_conv2d)\n",
        "\n",
        "# strided conv2d model\n",
        "layers.append(tf.keras.layers.Conv2D(12,3,strides=5)(pictures))\n",
        "strided_conv2d = tf.keras.Model(inputs=pictures,outputs=layers[-1],name=\"strided_conv2d\")\n",
        "models.append(strided_conv2d)\n",
        "\n",
        "# big conv2d model\n",
        "layers.append(tf.keras.layers.Conv2D(9,7)(pictures))\n",
        "big_conv2d = tf.keras.Model(inputs=pictures,outputs=layers[-1],name=\"big_conv2d\")\n",
        "models.append(big_conv2d)\n",
        "\n",
        "# small conv2d model\n",
        "layers.append(tf.keras.layers.Conv2D(9,3)(pictures))\n",
        "small_conv2d = tf.keras.Model(inputs=pictures,outputs=layers[-1],name=\"small_conv2d\")\n",
        "models.append(small_conv2d)\n",
        "\n",
        "# many conv2d model\n",
        "layers.append(tf.keras.layers.Conv2D(512,3)(pictures))\n",
        "many_conv2d = tf.keras.Model(inputs=pictures,outputs=layers[-1],name=\"many_conv2d\")\n",
        "models.append(many_conv2d)\n",
        "\n",
        "# few conv2d model\n",
        "layers.append(tf.keras.layers.Conv2D(3,3)(pictures))\n",
        "few_conv2d = tf.keras.Model(inputs=pictures,outputs=layers[-1],name=\"few_conv2d\")\n",
        "models.append(few_conv2d)\n",
        "\n",
        "\n",
        "# convert and store models\n",
        "if not os.path.isdir(\"TF_Lite-Models\"): os.mkdir(\"TF_Lite-Models\")\n",
        "if not os.path.isdir(\"Tensor_Flow-Models\"): os.mkdir(\"Tensor_Flow-Models\")\n",
        "for model in models:\n",
        "  model.save((\"Tensor_Flow-Models/\"+model.name))\n",
        "  with open((\"TF_Lite-Models/\"+model.name+\".tflite\"), 'wb') as model_file:\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    tflite_model = converter.convert()\n",
        "    model_file.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "relu_act.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgdK_wQaRpkx",
        "outputId": "1d74ef15-1375-4725-96ad-88eb7cf605e0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"relu_act\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(512, 128)]              0         \n",
            "                                                                 \n",
            " activation (Activation)     (512, 128)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "leaky_relu_act.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDsrYzaTSNUf",
        "outputId": "7bb6ccac-16a6-4320-f439-9ee15481d786"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"leaky_relu_act\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(512, 128)]              0         \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (512, 128)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tanh_act.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LIizkI2SShh",
        "outputId": "8dd36142-0f39-4a8b-fc8b-9e2166ebc512"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tanh_act\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(512, 128)]              0         \n",
            "                                                                 \n",
            " activation_1 (Activation)   (512, 128)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sigmoid_act.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjPUgCUVSYPT",
        "outputId": "c07894ba-ba21-4a5c-a73f-038f84860825"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sigmoid_act\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(512, 128)]              0         \n",
            "                                                                 \n",
            " activation_2 (Activation)   (512, 128)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scalar_mult.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdvQuGWvSbsm",
        "outputId": "56f3430e-eefc-4868-9dee-a4939023c460"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"scalar_mult\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(512, 128)]              0         \n",
            "                                                                 \n",
            " lambda (Lambda)             (512, 128)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_dense.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeKOcyyrSqJg",
        "outputId": "60c3a8a9-d346-46cd-e09d-4c623054d3ee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"small_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(512, 128)]              0         \n",
            "                                                                 \n",
            " dense (Dense)               (512, 8)                  1032      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,032\n",
            "Trainable params: 1,032\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "big_dense.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANDbMUZISt14",
        "outputId": "5a67ecb9-fbd6-45ef-fb97-9145ae7b50ad"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"big_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(512, 128)]              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (512, 512)                66048     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66,048\n",
            "Trainable params: 66,048\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simple_conv2d.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPqQH5zoS0zI",
        "outputId": "a7974cb6-7354-4331-d994-3d21ee011e0b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"simple_conv2d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(512, 128, 128, 3)]      0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (512, 126, 126, 12)       336       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 336\n",
            "Trainable params: 336\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strided_conv2d.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjZdM_V3TCHw",
        "outputId": "ff08927f-aa58-49d4-cf08-b486a7289dc9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"strided_conv2d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(512, 128, 128, 3)]      0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (512, 26, 26, 12)         336       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 336\n",
            "Trainable params: 336\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dilated_conv2d.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ94bUPnTIpV",
        "outputId": "e264bd9d-ff25-4031-dfc3-993877259eb5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"dilated_conv2d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(512, 128, 128, 3)]      0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (512, 124, 124, 12)       336       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 336\n",
            "Trainable params: 336\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_conv2d.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUgEY74jTMMQ",
        "outputId": "475a7ea3-260d-4f44-cf27-42933410b8c0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"small_conv2d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(512, 128, 128, 3)]      0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (512, 126, 126, 9)        252       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 252\n",
            "Trainable params: 252\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "big_conv2d.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi_su7zlTR03",
        "outputId": "24bafe04-1504-43f4-d30a-a694b2810889"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"big_conv2d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(512, 128, 128, 3)]      0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (512, 122, 122, 9)        1332      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,332\n",
            "Trainable params: 1,332\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "few_conv2d.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtOgM2c4nfLl",
        "outputId": "7a790a80-8bae-4a5b-a28d-2b40ccae08c4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"few_conv2d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(512, 128, 128, 3)]      0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (512, 126, 126, 3)        84        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 84\n",
            "Trainable params: 84\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "many_conv2d.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv_9L3KHnkrn",
        "outputId": "5ef79ff4-5ca3-4efa-a187-346454a65309"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"many_conv2d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(512, 128, 128, 3)]      0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (512, 126, 126, 512)      14336     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,336\n",
            "Trainable params: 14,336\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compile Models for OpenVINO"
      ],
      "metadata": {
        "id": "MFoqrBB_Ehxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://apt.repos.intel.com/openvino/2021/GPG-PUB-KEY-INTEL-OPENVINO-2021\n",
        "!sudo apt-key add GPG-PUB-KEY-INTEL-OPENVINO-2021\n",
        "!echo \"deb https://apt.repos.intel.com/openvino/2021 all main\" | sudo tee /etc/apt/sources.list.d/intel-openvino-2021.list\n",
        "!sudo apt update > /dev/null $2>&1\n",
        "!sudo apt install intel-openvino-dev-ubuntu20-2021.3.394 -y > /dev/null $2>&1\n",
        "!bash /opt/intel/openvino_2021/bin/setupvars.sh\n",
        "!python3 -m pip install openvino-dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GV2wp6rpl94p",
        "outputId": "555f7611-21ce-46cc-d6c7-99e53323b619"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-30 02:06:59--  https://apt.repos.intel.com/openvino/2021/GPG-PUB-KEY-INTEL-OPENVINO-2021\n",
            "Resolving apt.repos.intel.com (apt.repos.intel.com)... 23.218.183.111, 2600:1402:f000:1081::4b23, 2600:1402:f000:1082::4b23\n",
            "Connecting to apt.repos.intel.com (apt.repos.intel.com)|23.218.183.111|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 939 [binary/octet-stream]\n",
            "Saving to: ‘GPG-PUB-KEY-INTEL-OPENVINO-2021’\n",
            "\n",
            "GPG-PUB-KEY-INTEL-O 100%[===================>]     939  --.-KB/s    in 0s      \n",
            "\n",
            "2022-01-30 02:07:00 (155 MB/s) - ‘GPG-PUB-KEY-INTEL-OPENVINO-2021’ saved [939/939]\n",
            "\n",
            "OK\n",
            "deb https://apt.repos.intel.com/openvino/2021 all main\n",
            "[setupvars.sh] OpenVINO environment initialized\n",
            "Collecting openvino-dev\n",
            "  Downloading openvino_dev-2021.4.2-3976-py3-none-any.whl (6.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.2 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: hyperopt~=0.1.2 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (0.1.2)\n",
            "Collecting pydicom>=2.1.2\n",
            "  Downloading pydicom-2.2.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 43.5 MB/s \n",
            "\u001b[?25hCollecting sentencepiece>=0.1.95\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 45.5 MB/s \n",
            "\u001b[?25hCollecting opencv-python==4.5.*\n",
            "  Downloading opencv_python-4.5.5.62-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 60.4 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting rawpy>=0.16.0\n",
            "  Downloading rawpy-0.17.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 50.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: shapely>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (1.8.0)\n",
            "Collecting texttable~=1.6.3\n",
            "  Downloading texttable-1.6.4-py2.py3-none-any.whl (10 kB)\n",
            "Collecting openvino==2021.4.2\n",
            "  Downloading openvino-2021.4.2-3976-cp37-cp37m-manylinux2014_x86_64.whl (28.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 28.9 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: editdistance>=0.5.3 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (0.5.3)\n",
            "Requirement already satisfied: networkx~=2.5 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (2.6.3)\n",
            "Collecting jstyleson~=0.0.2\n",
            "  Downloading jstyleson-0.0.2.tar.gz (2.0 kB)\n",
            "Collecting pillow>=8.1.2\n",
            "  Downloading Pillow-9.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 56.7 MB/s \n",
            "\u001b[?25hCollecting scipy~=1.5.4\n",
            "  Downloading scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting yamlloader>=0.5\n",
            "  Downloading yamlloader-1.1.0-py3-none-any.whl (6.6 kB)\n",
            "Requirement already satisfied: scikit-image>=0.17.2 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (0.18.3)\n",
            "Collecting progress>=1.5\n",
            "  Downloading progress-1.6.tar.gz (7.8 kB)\n",
            "Requirement already satisfied: pandas~=1.1.5 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (1.1.5)\n",
            "Collecting requests>=2.25.1\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.1 MB/s \n",
            "\u001b[?25hCollecting fast-ctc-decode>=0.2.5\n",
            "  Downloading fast_ctc_decode-0.3.0-cp37-cp37m-manylinux2010_x86_64.whl (508 kB)\n",
            "\u001b[K     |████████████████████████████████| 508 kB 53.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<1.20,>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (1.19.5)\n",
            "Collecting py-cpuinfo>=7.0.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 6.1 MB/s \n",
            "\u001b[?25hCollecting addict>=2.4.0\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (0.7.1)\n",
            "Collecting PyYAML>=5.4.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 44.6 MB/s \n",
            "\u001b[?25hCollecting tokenizers>=0.10.1\n",
            "  Downloading tokenizers-0.11.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 56.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.54.1 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (4.62.3)\n",
            "Collecting parasail>=1.2.4\n",
            "  Downloading parasail-1.2.4-py2.py3-none-manylinux2010_x86_64.whl (14.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.1 MB 142 kB/s \n",
            "\u001b[?25hCollecting nibabel>=3.2.1\n",
            "  Downloading nibabel-3.2.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 27.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (1.0.2)\n",
            "Collecting nltk>=3.5\n",
            "  Downloading nltk-3.6.7-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 51.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt~=0.1.2->openvino-dev) (0.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt~=0.1.2->openvino-dev) (4.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hyperopt~=0.1.2->openvino-dev) (1.15.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from nibabel>=3.2.1->openvino-dev) (21.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.5->openvino-dev) (7.1.2)\n",
            "Collecting regex>=2021.8.3\n",
            "  Downloading regex-2022.1.18-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (748 kB)\n",
            "\u001b[K     |████████████████████████████████| 748 kB 45.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.5->openvino-dev) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->nibabel>=3.2.1->openvino-dev) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas~=1.1.5->openvino-dev) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas~=1.1.5->openvino-dev) (2018.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->openvino-dev) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->openvino-dev) (2.0.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->openvino-dev) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->openvino-dev) (2021.10.8)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2->openvino-dev) (2.4.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2->openvino-dev) (3.2.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2->openvino-dev) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2->openvino-dev) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17.2->openvino-dev) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17.2->openvino-dev) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.1->openvino-dev) (3.0.0)\n",
            "Building wheels for collected packages: jstyleson, progress, py-cpuinfo\n",
            "  Building wheel for jstyleson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jstyleson: filename=jstyleson-0.0.2-py3-none-any.whl size=2402 sha256=75f7834192a382282a34896ea76707babd181c291f902f1f31602abfa0cb0950\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/8e/03/d5962b9032cc1b638d1891a3bfbfdc6627cac531754f79ef23\n",
            "  Building wheel for progress (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progress: filename=progress-1.6-py3-none-any.whl size=9632 sha256=ae22d6eda9ed985afa29312066959c72d84ef9c1a734e2eda1a2bc3c80b243e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/d7/61/498d8e27dc11e9805b01eb3539e2ee344436fc226daeb5fe87\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=d50c3d986507f4f6b33b64e2c5aaaaaa095491125e4f100bc6019d56e3cae10a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "Successfully built jstyleson progress py-cpuinfo\n",
            "Installing collected packages: pillow, scipy, regex, PyYAML, yamlloader, tokenizers, texttable, sentencepiece, requests, rawpy, pydicom, py-cpuinfo, progress, parasail, openvino, opencv-python, nltk, nibabel, jstyleson, fast-ctc-decode, addict, openvino-dev\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Attempting uninstall: nibabel\n",
            "    Found existing installation: nibabel 3.0.2\n",
            "    Uninstalling nibabel-3.0.2:\n",
            "      Successfully uninstalled nibabel-3.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed PyYAML-6.0 addict-2.4.0 fast-ctc-decode-0.3.0 jstyleson-0.0.2 nibabel-3.2.1 nltk-3.6.7 opencv-python-4.5.5.62 openvino-2021.4.2 openvino-dev-2021.4.2 parasail-1.2.4 pillow-9.0.0 progress-1.6 py-cpuinfo-8.0.0 pydicom-2.2.2 rawpy-0.17.0 regex-2022.1.18 requests-2.27.1 scipy-1.5.4 sentencepiece-0.1.96 texttable-1.6.4 tokenizers-0.11.4 yamlloader-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.isdir(\"OpenVINO-Models\"): os.mkdir(\"OpenVINO-Models\")\n",
        "for model in models:\n",
        "  result = subprocess.run(['python3', '-m', 'mo', '--framework', 'tf',\n",
        "                           '--progress', '--input_model_is_text',\n",
        "                           '--batch', str(BatchSize), '--input_shape',\n",
        "                           str(model.get_layer(index=0).input_shape),\n",
        "                           '--data_type=FP16', '--model_name', model.name, \n",
        "                           '--saved_model_dir', \n",
        "                           current_dir+'/Tensor_Flow-Models/'+model.name,\n",
        "                           '--output_dir', current_dir+'/OpenVINO-Models'],\n",
        "                          stdout=subprocess.PIPE)\n",
        "  print(result.stdout.decode('ascii'))                      "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29vSSMp0EntP",
        "outputId": "900889f6-b2e8-4645-a15c-c18f21b6bdc1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \trelu_act\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t512\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(512, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tleaky_relu_act\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t512\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(512, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \ttanh_act\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t512\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(512, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tsigmoid_act\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t512\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(512, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tscalar_mult\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t512\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(512, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tsmall_dense\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t512\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(512, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tbig_dense\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t512\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(512, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tsimple_conv2d\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t512\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(512, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tdilated_conv2d\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t512\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(512, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tstrided_conv2d\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t512\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(512, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tbig_conv2d\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t512\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(512, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tsmall_conv2d\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t512\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(512, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tmany_conv2d\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t512\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(512, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tfew_conv2d\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t512\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(512, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compile Models for Edge TPU"
      ],
      "metadata": {
        "id": "ctTk4Hf8qp8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "!echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install edgetpu-compiler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiRFwaK7mVyh",
        "outputId": "10c0e564-a745-4138-b0b1-532cd446e06a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2537  100  2537    0     0   103k      0 --:--:-- --:--:-- --:--:--   99k\n",
            "OK\n",
            "deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\n",
            "Hit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 https://apt.repos.intel.com/openvino/2021 all InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:17 https://packages.cloud.google.com/apt coral-edgetpu-stable InRelease [6,722 B]\n",
            "Get:18 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 Packages [2,327 B]\n",
            "Fetched 9,049 B in 3s (2,641 B/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  edgetpu-compiler\n",
            "0 upgraded, 1 newly installed, 0 to remove and 64 not upgraded.\n",
            "Need to get 7,913 kB of archives.\n",
            "After this operation, 31.2 MB of additional disk space will be used.\n",
            "Get:1 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 edgetpu-compiler amd64 16.0 [7,913 kB]\n",
            "Fetched 7,913 kB in 1s (11.1 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package edgetpu-compiler.\n",
            "(Reading database ... 161476 files and directories currently installed.)\n",
            "Preparing to unpack .../edgetpu-compiler_16.0_amd64.deb ...\n",
            "Unpacking edgetpu-compiler (16.0) ...\n",
            "Setting up edgetpu-compiler (16.0) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.isdir(\"Edge_TPU-Models\"): os.mkdir(\"Edge_TPU-Models\")\n",
        "\n",
        "filenames = \"\"\n",
        "for model in models:\n",
        "  filenames += \" \"+current_dir+\"/TF_Lite-Models/\"+model.name+\".tflite\"\n",
        "result = subprocess.run(['edgetpu_compiler','-s','-o',\n",
        "                         current_dir+'/Edge_TPU-Models',*filenames.split()],\n",
        "                        stdout=subprocess.PIPE)\n",
        "print(result.stdout.decode('ascii'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhkBIlpWq76r",
        "outputId": "2e5ca3d1-3071-4fc7-9e7a-a69d726caba4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edge TPU Compiler version 16.0.384591198\n",
            "Started a compilation timeout timer of 180 seconds.\n",
            "\n",
            "Models compiled successfully in 15 ms.\n",
            "\n",
            "Input model: /content/TF_Lite-Models/relu_act.tflite\n",
            "Input size: 640.00B\n",
            "Output model: /content/Edge_TPU-Models/relu_act_edgetpu.tflite\n",
            "Output size: 372.00B\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 0\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/relu_act_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 0\n",
            "Number of operations that will run on CPU: 1\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "RELU                           1          Operation is working on an unsupported data type\n",
            "\n",
            "Input model: /content/TF_Lite-Models/leaky_relu_act.tflite\n",
            "Input size: 660.00B\n",
            "Output model: /content/Edge_TPU-Models/leaky_relu_act_edgetpu.tflite\n",
            "Output size: 392.00B\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 0\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/leaky_relu_act_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 0\n",
            "Number of operations that will run on CPU: 1\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "LEAKY_RELU                     1          Operation is working on an unsupported data type\n",
            "\n",
            "Input model: /content/TF_Lite-Models/tanh_act.tflite\n",
            "Input size: 644.00B\n",
            "Output model: /content/Edge_TPU-Models/tanh_act_edgetpu.tflite\n",
            "Output size: 372.00B\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 0\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/tanh_act_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 0\n",
            "Number of operations that will run on CPU: 1\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "TANH                           1          Operation is working on an unsupported data type\n",
            "\n",
            "Input model: /content/TF_Lite-Models/sigmoid_act.tflite\n",
            "Input size: 644.00B\n",
            "Output model: /content/Edge_TPU-Models/sigmoid_act_edgetpu.tflite\n",
            "Output size: 372.00B\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 0\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/sigmoid_act_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 0\n",
            "Number of operations that will run on CPU: 1\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "LOGISTIC                       1          Operation is working on an unsupported data type\n",
            "\n",
            "Input model: /content/TF_Lite-Models/scalar_mult.tflite\n",
            "Input size: 740.00B\n",
            "Output model: /content/Edge_TPU-Models/scalar_mult_edgetpu.tflite\n",
            "Output size: 484.00B\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 0\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/scalar_mult_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 0\n",
            "Number of operations that will run on CPU: 1\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "MUL                            1          Operation is working on an unsupported data type\n",
            "\n",
            "Input model: /content/TF_Lite-Models/small_dense.tflite\n",
            "Input size: 4.74KiB\n",
            "Output model: /content/Edge_TPU-Models/small_dense_edgetpu.tflite\n",
            "Output size: 4.49KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 0\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/small_dense_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 0\n",
            "Number of operations that will run on CPU: 1\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "FULLY_CONNECTED                1          Operation is working on an unsupported data type\n",
            "\n",
            "Input model: /content/TF_Lite-Models/big_dense.tflite\n",
            "Input size: 256.74KiB\n",
            "Output model: /content/Edge_TPU-Models/big_dense_edgetpu.tflite\n",
            "Output size: 256.49KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 0\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/big_dense_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 0\n",
            "Number of operations that will run on CPU: 1\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "FULLY_CONNECTED                1          Operation is working on an unsupported data type\n",
            "\n",
            "Input model: /content/TF_Lite-Models/simple_conv2d.tflite\n",
            "Input size: 2.21KiB\n",
            "Output model: /content/Edge_TPU-Models/simple_conv2d_edgetpu.tflite\n",
            "Output size: 1.95KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 0\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/simple_conv2d_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 0\n",
            "Number of operations that will run on CPU: 1\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        1          Tensor has unsupported rank (up to 3 innermost dimensions mapped)\n",
            "\n",
            "Input model: /content/TF_Lite-Models/dilated_conv2d.tflite\n",
            "Input size: 2.23KiB\n",
            "Output model: /content/Edge_TPU-Models/dilated_conv2d_edgetpu.tflite\n",
            "Output size: 1.97KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 0\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/dilated_conv2d_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 0\n",
            "Number of operations that will run on CPU: 1\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        1          Tensor has unsupported rank (up to 3 innermost dimensions mapped)\n",
            "\n",
            "Input model: /content/TF_Lite-Models/strided_conv2d.tflite\n",
            "Input size: 2.22KiB\n",
            "Output model: /content/Edge_TPU-Models/strided_conv2d_edgetpu.tflite\n",
            "Output size: 1.96KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 0\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/strided_conv2d_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 0\n",
            "Number of operations that will run on CPU: 1\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        1          Tensor has unsupported rank (up to 3 innermost dimensions mapped)\n",
            "\n",
            "Input model: /content/TF_Lite-Models/big_conv2d.tflite\n",
            "Input size: 6.10KiB\n",
            "Output model: /content/Edge_TPU-Models/big_conv2d_edgetpu.tflite\n",
            "Output size: 5.84KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 0\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/big_conv2d_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 0\n",
            "Number of operations that will run on CPU: 1\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        1          Tensor has unsupported rank (up to 3 innermost dimensions mapped)\n",
            "\n",
            "Input model: /content/TF_Lite-Models/small_conv2d.tflite\n",
            "Input size: 1.89KiB\n",
            "Output model: /content/Edge_TPU-Models/small_conv2d_edgetpu.tflite\n",
            "Output size: 1.62KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 0\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/small_conv2d_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 0\n",
            "Number of operations that will run on CPU: 1\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        1          Tensor has unsupported rank (up to 3 innermost dimensions mapped)\n",
            "\n",
            "Input model: /content/TF_Lite-Models/many_conv2d.tflite\n",
            "Input size: 56.90KiB\n",
            "Output model: /content/Edge_TPU-Models/many_conv2d_edgetpu.tflite\n",
            "Output size: 56.64KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 0\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/many_conv2d_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 0\n",
            "Number of operations that will run on CPU: 1\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        1          Tensor has unsupported rank (up to 3 innermost dimensions mapped)\n",
            "\n",
            "Input model: /content/TF_Lite-Models/few_conv2d.tflite\n",
            "Input size: 1.23KiB\n",
            "Output model: /content/Edge_TPU-Models/few_conv2d_edgetpu.tflite\n",
            "Output size: 984.00B\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 0\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/few_conv2d_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 0\n",
            "Number of operations that will run on CPU: 1\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        1          Tensor has unsupported rank (up to 3 innermost dimensions mapped)\n",
            "Compilation child process completed within timeout period.\n",
            "Compilation succeeded! \n",
            "\n"
          ]
        }
      ]
    }
  ]
}