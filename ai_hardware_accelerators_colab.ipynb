{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nils-Treuheit/Heterogenous-Inferencing/blob/main/ai_hardware_accelerators_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDplXLeYwNNy"
      },
      "source": [
        "#Create Simple Tensorflow Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4ghjtz04EoA-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os, subprocess\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "BatchSize = 1 #512\n",
        "picture_shape = (128,128,3)\n",
        "linear_data_shape = (128)\n",
        "pictures = tf.keras.Input(shape=picture_shape, batch_size=BatchSize)\n",
        "linear_data = tf.keras.Input(shape=linear_data_shape, batch_size=BatchSize)\n",
        "layers,models = ([],[])\n",
        "\n",
        "\n",
        "# relu activation model\n",
        "layers.append(tf.keras.layers.Activation('relu')(linear_data))\n",
        "relu_act = tf.keras.Model(inputs=linear_data,outputs=layers[-1],name=\"relu_act\")\n",
        "models.append(relu_act)\n",
        "\n",
        "# leaky relu activation model\n",
        "layers.append(tf.keras.layers.LeakyReLU()(linear_data))\n",
        "leaky_relu_act = tf.keras.Model(inputs=linear_data,outputs=layers[-1],name=\"leaky_relu_act\")\n",
        "models.append(leaky_relu_act)\n",
        "\n",
        "# tanh activation model\n",
        "layers.append(tf.keras.layers.Activation('tanh')(linear_data))\n",
        "tanh_act = tf.keras.Model(inputs=linear_data,outputs=layers[-1],name=\"tanh_act\")\n",
        "models.append(tanh_act)\n",
        "\n",
        "# sigmoid activation model\n",
        "layers.append(tf.keras.layers.Activation('sigmoid')(linear_data))\n",
        "sigmoid_act = tf.keras.Model(inputs=linear_data,outputs=layers[-1],name=\"sigmoid_act\")\n",
        "models.append(sigmoid_act)\n",
        "\n",
        "# scalar_multiply model\n",
        "layers.append(tf.keras.layers.Lambda(lambda x: x * 5.0)(linear_data))\n",
        "scalar_mult = tf.keras.Model(inputs=linear_data,outputs=layers[-1],name=\"scalar_mult\")\n",
        "models.append(scalar_mult)\n",
        "\n",
        "# small dense model\n",
        "layers.append(tf.keras.layers.Dense(8)(linear_data))\n",
        "small_dense = tf.keras.Model(inputs=linear_data,outputs=layers[-1],name=\"small_dense\")\n",
        "models.append(small_dense)\n",
        "\n",
        "# big dense model\n",
        "layers.append(tf.keras.layers.Dense(512)(linear_data))\n",
        "big_dense = tf.keras.Model(inputs=linear_data,outputs=layers[-1],name=\"big_dense\")\n",
        "models.append(big_dense)\n",
        "\n",
        "# simple conv2d model\n",
        "layers.append(tf.keras.layers.Conv2D(12,3)(pictures))\n",
        "simple_conv2d = tf.keras.Model(inputs=pictures,outputs=layers[-1],name=\"simple_conv2d\")\n",
        "models.append(simple_conv2d)\n",
        "\n",
        "# dilated conv2d model\n",
        "layers.append(tf.keras.layers.Conv2D(12,3,dilation_rate=2)(pictures))\n",
        "dilated_conv2d = tf.keras.Model(inputs=pictures,outputs=layers[-1],name=\"dilated_conv2d\")\n",
        "models.append(dilated_conv2d)\n",
        "\n",
        "# strided conv2d model\n",
        "layers.append(tf.keras.layers.Conv2D(12,3,strides=5)(pictures))\n",
        "strided_conv2d = tf.keras.Model(inputs=pictures,outputs=layers[-1],name=\"strided_conv2d\")\n",
        "models.append(strided_conv2d)\n",
        "\n",
        "# big conv2d model\n",
        "layers.append(tf.keras.layers.Conv2D(9,7)(pictures))\n",
        "big_conv2d = tf.keras.Model(inputs=pictures,outputs=layers[-1],name=\"big_conv2d\")\n",
        "models.append(big_conv2d)\n",
        "\n",
        "# small conv2d model\n",
        "layers.append(tf.keras.layers.Conv2D(9,3)(pictures))\n",
        "small_conv2d = tf.keras.Model(inputs=pictures,outputs=layers[-1],name=\"small_conv2d\")\n",
        "models.append(small_conv2d)\n",
        "\n",
        "# many conv2d model\n",
        "layers.append(tf.keras.layers.Conv2D(256,3)(pictures))\n",
        "many_conv2d = tf.keras.Model(inputs=pictures,outputs=layers[-1],name=\"many_conv2d\")\n",
        "models.append(many_conv2d)\n",
        "\n",
        "# few conv2d model\n",
        "layers.append(tf.keras.layers.Conv2D(3,3)(pictures))\n",
        "few_conv2d = tf.keras.Model(inputs=pictures,outputs=layers[-1],name=\"few_conv2d\")\n",
        "models.append(few_conv2d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgdK_wQaRpkx",
        "outputId": "7cb1f027-85b1-491d-ca89-9221f0e76379"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"relu_act\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(512, 128)]              0         \n",
            "                                                                 \n",
            " activation (Activation)     (512, 128)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "relu_act.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDsrYzaTSNUf",
        "outputId": "e11a2334-a451-4e02-b1fc-886ce6e03563"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"leaky_relu_act\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(512, 128)]              0         \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (512, 128)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "leaky_relu_act.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LIizkI2SShh",
        "outputId": "da329497-810c-4551-de43-67c511ede654"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"tanh_act\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(512, 128)]              0         \n",
            "                                                                 \n",
            " activation_1 (Activation)   (512, 128)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "tanh_act.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjPUgCUVSYPT",
        "outputId": "07ee4b02-9faf-4918-dd31-6649946ba00f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sigmoid_act\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(512, 128)]              0         \n",
            "                                                                 \n",
            " activation_2 (Activation)   (512, 128)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "sigmoid_act.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdvQuGWvSbsm",
        "outputId": "49df80fe-4fa8-4cd0-8beb-947f0c5abf31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"scalar_mult\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(512, 128)]              0         \n",
            "                                                                 \n",
            " lambda (Lambda)             (512, 128)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "scalar_mult.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeKOcyyrSqJg",
        "outputId": "b6534318-f850-485e-d34a-b03f3c14d681"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"small_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(512, 128)]              0         \n",
            "                                                                 \n",
            " dense (Dense)               (512, 8)                  1032      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,032\n",
            "Trainable params: 1,032\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "small_dense.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANDbMUZISt14",
        "outputId": "c76a0168-5443-4794-b8a3-3134b4d1d0dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"big_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(512, 128)]              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (512, 512)                66048     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66,048\n",
            "Trainable params: 66,048\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "big_dense.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPqQH5zoS0zI",
        "outputId": "6e30491c-12fe-4ee2-b5bf-54054544e51b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"simple_conv2d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(512, 128, 128, 3)]      0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (512, 126, 126, 12)       336       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 336\n",
            "Trainable params: 336\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "simple_conv2d.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjZdM_V3TCHw",
        "outputId": "06c219c7-b4c4-4159-e1d9-f017ef4f125d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"strided_conv2d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(512, 128, 128, 3)]      0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (512, 26, 26, 12)         336       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 336\n",
            "Trainable params: 336\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "strided_conv2d.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ94bUPnTIpV",
        "outputId": "7980ad9f-fe1a-45f2-c3ca-d866f9faad23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"dilated_conv2d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(512, 128, 128, 3)]      0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (512, 124, 124, 12)       336       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 336\n",
            "Trainable params: 336\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "dilated_conv2d.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUgEY74jTMMQ",
        "outputId": "a37286ac-ed2d-4e13-8d4a-4d839838f9d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"small_conv2d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(512, 128, 128, 3)]      0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (512, 126, 126, 9)        252       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 252\n",
            "Trainable params: 252\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "small_conv2d.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi_su7zlTR03",
        "outputId": "80cd6208-7271-4d4b-cf4d-cea6c70defac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"big_conv2d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(512, 128, 128, 3)]      0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (512, 122, 122, 9)        1332      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,332\n",
            "Trainable params: 1,332\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "big_conv2d.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtOgM2c4nfLl",
        "outputId": "a4083ce6-1c81-46fa-f294-4883fe07d740"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"few_conv2d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(512, 128, 128, 3)]      0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (512, 126, 126, 3)        84        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 84\n",
            "Trainable params: 84\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "few_conv2d.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv_9L3KHnkrn",
        "outputId": "fad8ba94-3799-4e66-f0ea-3999621312d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"many_conv2d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(512, 128, 128, 3)]      0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (512, 126, 126, 256)      7168      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,168\n",
            "Trainable params: 7,168\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "many_conv2d.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ_1pEovIYsf"
      },
      "source": [
        "#Convert and Store TF-Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVjJhvHnIZWK",
        "outputId": "4328f1a1-5aff-4283-b81b-ea3f210f2b74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/relu_act/assets\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpc3umsku8/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/leaky_relu_act/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/leaky_relu_act/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmppi35cot6/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmppi35cot6/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/tanh_act/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/tanh_act/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpykmp8s18/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpykmp8s18/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/sigmoid_act/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/sigmoid_act/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpbgem4kyj/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpbgem4kyj/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/scalar_mult/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/scalar_mult/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpxxlv_mqt/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpxxlv_mqt/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/small_dense/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/small_dense/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpn7dsmsp1/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpn7dsmsp1/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/big_dense/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/big_dense/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmppngyx9yu/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmppngyx9yu/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/simple_conv2d/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/simple_conv2d/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpr21uyavh/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpr21uyavh/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/dilated_conv2d/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/dilated_conv2d/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp_uzjpk3k/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp_uzjpk3k/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/strided_conv2d/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/strided_conv2d/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpmhkupr3k/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpmhkupr3k/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/big_conv2d/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/big_conv2d/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpyozo1f0z/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpyozo1f0z/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/small_conv2d/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/small_conv2d/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpa1lc1ce8/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpa1lc1ce8/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/many_conv2d/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/many_conv2d/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpewr9w88m/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpewr9w88m/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/few_conv2d/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/few_conv2d/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp6zewpdal/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp6zewpdal/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "relu_act\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpwo04la2s/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpwo04la2s/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "leaky_relu_act\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp36_95n9m/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp36_95n9m/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tanh_act\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpvn76s8hj/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpvn76s8hj/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sigmoid_act\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp0t0zaewi/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp0t0zaewi/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "scalar_mult\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpckrkc4jj/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpckrkc4jj/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "small_dense\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp82lwwgt0/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp82lwwgt0/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "big_dense\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpquvjvqej/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpquvjvqej/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "simple_conv2d\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpf9ea2a7b/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpf9ea2a7b/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dilated_conv2d\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpp3xfgrl2/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpp3xfgrl2/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "strided_conv2d\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp609b9j0r/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp609b9j0r/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "big_conv2d\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp16xq7sgu/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp16xq7sgu/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "small_conv2d\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp06a091r0/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp06a091r0/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "many_conv2d\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp3j3r107t/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp3j3r107t/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "few_conv2d\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpl2fomvty/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpl2fomvty/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ],
      "source": [
        "if not os.path.isdir(\"TF_Lite-Models\"): os.mkdir(\"TF_Lite-Models\")\n",
        "if not os.path.isdir(\"Tensor_Flow-Models\"): os.mkdir(\"Tensor_Flow-Models\")\n",
        "for model in models:\n",
        "  model.save((\"Tensor_Flow-Models/\"+model.name))\n",
        "  with open((\"TF_Lite-Models/\"+model.name+\".tflite\"), 'wb') as model_file:\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    tflite_model = converter.convert()\n",
        "    model_file.write(tflite_model)\n",
        "for model in models:\n",
        "  print(model.name)\n",
        "  with open((\"TF_Lite-Models/\"+model.name+\"_int8.tflite\"), 'wb') as model_file:\n",
        "    tmp_shape=model.get_layer(index=0).input_shape[0]\n",
        "    data_gen=lambda : (yield [tf.random.uniform(shape=tmp_shape,dtype=tf.dtypes.float32)])\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    converter.optimizations=[tf.lite.Optimize.DEFAULT]\n",
        "    converter.inference_input_type=tf.int8\n",
        "    converter.inference_output_type=tf.int8\n",
        "    converter.target_spec.supported_ops=[tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "    converter.representative_dataset=data_gen\n",
        "    tflite_model = converter.convert()\n",
        "    model_file.write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFoqrBB_Ehxb"
      },
      "source": [
        "#Compile Models for OpenVINO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GV2wp6rpl94p",
        "outputId": "82755ae1-4307-48ae-9adb-cf465ae23b72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-02-27 20:03:38--  https://apt.repos.intel.com/openvino/2021/GPG-PUB-KEY-INTEL-OPENVINO-2021\n",
            "Resolving apt.repos.intel.com (apt.repos.intel.com)... 23.218.183.111, 2600:1402:3800:2aa::4b23, 2600:1402:3800:2ab::4b23\n",
            "Connecting to apt.repos.intel.com (apt.repos.intel.com)|23.218.183.111|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 939 [binary/octet-stream]\n",
            "Saving to: GPG-PUB-KEY-INTEL-OPENVINO-2021.1\n",
            "\n",
            "GPG-PUB-KEY-INTEL-O 100%[===================>]     939  --.-KB/s    in 0s      \n",
            "\n",
            "2022-02-27 20:03:39 (123 MB/s) - GPG-PUB-KEY-INTEL-OPENVINO-2021.1 saved [939/939]\n",
            "\n",
            "OK\n",
            "deb https://apt.repos.intel.com/openvino/2021 all main\n",
            "[setupvars.sh] OpenVINO environment initialized\n",
            "Requirement already satisfied: openvino-dev in /usr/local/lib/python3.7/dist-packages (2021.4.2)\n",
            "Requirement already satisfied: scipy~=1.5.4 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (1.5.4)\n",
            "Requirement already satisfied: py-cpuinfo>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (8.0.0)\n",
            "Requirement already satisfied: openvino==2021.4.2 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (2021.4.2)\n",
            "Requirement already satisfied: pandas~=1.1.5 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (1.1.5)\n",
            "Requirement already satisfied: nltk>=3.5 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (3.7)\n",
            "Requirement already satisfied: editdistance>=0.5.3 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (0.5.3)\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (1.0.2)\n",
            "Requirement already satisfied: rawpy>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (0.17.0)\n",
            "Requirement already satisfied: sentencepiece>=0.1.95 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (0.1.96)\n",
            "Requirement already satisfied: yamlloader>=0.5 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (1.1.0)\n",
            "Requirement already satisfied: hyperopt~=0.1.2 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (0.1.2)\n",
            "Requirement already satisfied: scikit-image>=0.17.2 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (0.18.3)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (6.0)\n",
            "Requirement already satisfied: numpy<1.20,>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (1.19.5)\n",
            "Requirement already satisfied: parasail>=1.2.4 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (1.2.4)\n",
            "Requirement already satisfied: nibabel>=3.2.1 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (3.2.2)\n",
            "Requirement already satisfied: progress>=1.5 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (1.6)\n",
            "Requirement already satisfied: pydicom>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (2.2.2)\n",
            "Requirement already satisfied: pillow>=8.1.2 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (9.0.1)\n",
            "Requirement already satisfied: opencv-python==4.5.* in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (4.5.5.62)\n",
            "Requirement already satisfied: jstyleson~=0.0.2 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (0.0.2)\n",
            "Requirement already satisfied: shapely>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (1.8.1)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (0.7.1)\n",
            "Requirement already satisfied: addict>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (2.4.0)\n",
            "Requirement already satisfied: tqdm>=4.54.1 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (4.62.3)\n",
            "Requirement already satisfied: fast-ctc-decode>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (0.3.0)\n",
            "Requirement already satisfied: requests>=2.25.1 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (2.27.1)\n",
            "Requirement already satisfied: networkx~=2.5 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (2.6.3)\n",
            "Requirement already satisfied: tokenizers>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (0.11.5)\n",
            "Requirement already satisfied: texttable~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (1.6.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hyperopt~=0.1.2->openvino-dev) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt~=0.1.2->openvino-dev) (0.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt~=0.1.2->openvino-dev) (4.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from nibabel>=3.2.1->openvino-dev) (57.4.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from nibabel>=3.2.1->openvino-dev) (21.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.5->openvino-dev) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.5->openvino-dev) (2022.1.18)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.5->openvino-dev) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->nibabel>=3.2.1->openvino-dev) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas~=1.1.5->openvino-dev) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas~=1.1.5->openvino-dev) (2018.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->openvino-dev) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->openvino-dev) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->openvino-dev) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->openvino-dev) (2021.10.8)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2->openvino-dev) (3.2.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2->openvino-dev) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2->openvino-dev) (1.2.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2->openvino-dev) (2.4.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17.2->openvino-dev) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17.2->openvino-dev) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.1->openvino-dev) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!wget https://apt.repos.intel.com/openvino/2021/GPG-PUB-KEY-INTEL-OPENVINO-2021\n",
        "!sudo apt-key add GPG-PUB-KEY-INTEL-OPENVINO-2021\n",
        "!echo \"deb https://apt.repos.intel.com/openvino/2021 all main\" | sudo tee /etc/apt/sources.list.d/intel-openvino-2021.list\n",
        "!sudo apt update > /dev/null $2>&1\n",
        "!sudo apt install intel-openvino-dev-ubuntu20-2021.3.394 -y > /dev/null $2>&1\n",
        "!bash /opt/intel/openvino_2021/bin/setupvars.sh\n",
        "!python3 -m pip install openvino-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29vSSMp0EntP",
        "outputId": "110f18fa-b6c9-45c8-e7ab-8323cb4e95d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \trelu_act\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t512\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(512, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tleaky_relu_act\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t512\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(512, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \ttanh_act\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t512\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(512, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tsigmoid_act\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t512\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(512, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tscalar_mult\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t512\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(512, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tsmall_dense\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t512\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(512, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tbig_dense\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t512\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(512, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tsimple_conv2d\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t512\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(512, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tdilated_conv2d\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t512\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(512, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tstrided_conv2d\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t512\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(512, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tbig_conv2d\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t512\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(512, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tsmall_conv2d\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t512\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(512, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tmany_conv2d\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t512\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(512, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tfew_conv2d\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t512\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(512, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if not os.path.isdir(\"OpenVINO-Models\"): os.mkdir(\"OpenVINO-Models\")\n",
        "for model in models:\n",
        "  result = subprocess.run(['python3', '-m', 'mo', '--framework', 'tf',\n",
        "                           '--progress', '--input_model_is_text',\n",
        "                           '--batch', str(BatchSize), '--input_shape',\n",
        "                           str(model.get_layer(index=0).input_shape),\n",
        "                           '--data_type=FP16', '--model_name', model.name, \n",
        "                           '--saved_model_dir', \n",
        "                           current_dir+'/Tensor_Flow-Models/'+model.name,\n",
        "                           '--output_dir', current_dir+'/OpenVINO-Models'],\n",
        "                          stdout=subprocess.PIPE)\n",
        "  print(result.stdout.decode('ascii'))                      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctTk4Hf8qp8q"
      },
      "source": [
        "#Compile Models for Edge TPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiRFwaK7mVyh",
        "outputId": "28b2403f-abf6-4857-e8ec-4c4aa3ac25e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2537  100  2537    0     0  74617      0 --:--:-- --:--:-- --:--:-- 74617\n",
            "OK\n",
            "deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\n",
            "Hit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Get:4 https://packages.cloud.google.com/apt coral-edgetpu-stable InRelease [6,722 B]\n",
            "Hit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:8 https://apt.repos.intel.com/openvino/2021 all InRelease\n",
            "Hit:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Ign:12 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 Packages\n",
            "Hit:13 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:15 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:18 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:12 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 Packages [2,327 B]\n",
            "Fetched 9,049 B in 1s (7,885 B/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-470\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  edgetpu-compiler\n",
            "0 upgraded, 1 newly installed, 0 to remove and 69 not upgraded.\n",
            "Need to get 7,913 kB of archives.\n",
            "After this operation, 31.2 MB of additional disk space will be used.\n",
            "Get:1 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 edgetpu-compiler amd64 16.0 [7,913 kB]\n",
            "Fetched 7,913 kB in 1s (6,877 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package edgetpu-compiler.\n",
            "(Reading database ... 161567 files and directories currently installed.)\n",
            "Preparing to unpack .../edgetpu-compiler_16.0_amd64.deb ...\n",
            "Unpacking edgetpu-compiler (16.0) ...\n",
            "Setting up edgetpu-compiler (16.0) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "!echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install edgetpu-compiler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhkBIlpWq76r",
        "outputId": "fd1a3c18-ea54-4d71-f5d0-7efd2f20e217"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Edge TPU Compiler version 16.0.384591198\n",
            "Started a compilation timeout timer of 180 seconds.\n",
            "\n",
            "Models compiled successfully in 545 ms.\n",
            "\n",
            "Input model: /content/TF_Lite-Models/relu_act_int8.tflite\n",
            "Input size: 712.00B\n",
            "Output model: /content/Edge_TPU-Models/relu_act_int8_edgetpu.tflite\n",
            "Output size: 28.59KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 6.05MiB\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/relu_act_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "RELU                           1          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/leaky_relu_act_int8.tflite\n",
            "Input size: 736.00B\n",
            "Output model: /content/Edge_TPU-Models/leaky_relu_act_int8_edgetpu.tflite\n",
            "Output size: 496.00B\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 0\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/leaky_relu_act_int8_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 0\n",
            "Number of operations that will run on CPU: 1\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "LEAKY_RELU                     1          Operation not supported\n",
            "\n",
            "Input model: /content/TF_Lite-Models/tanh_act_int8.tflite\n",
            "Input size: 720.00B\n",
            "Output model: /content/Edge_TPU-Models/tanh_act_int8_edgetpu.tflite\n",
            "Output size: 28.59KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 6.05MiB\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/tanh_act_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "TANH                           1          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/sigmoid_act_int8.tflite\n",
            "Input size: 720.00B\n",
            "Output model: /content/Edge_TPU-Models/sigmoid_act_int8_edgetpu.tflite\n",
            "Output size: 28.59KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 6.05MiB\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/sigmoid_act_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "LOGISTIC                       1          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/scalar_mult_int8.tflite\n",
            "Input size: 848.00B\n",
            "Output model: /content/Edge_TPU-Models/scalar_mult_int8_edgetpu.tflite\n",
            "Output size: 28.59KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 6.05MiB\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/scalar_mult_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "MUL                            1          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/small_dense_int8.tflite\n",
            "Input size: 1.84KiB\n",
            "Output model: /content/Edge_TPU-Models/small_dense_int8_edgetpu.tflite\n",
            "Output size: 48.59KiB\n",
            "On-chip memory used for caching model parameters: 8.00KiB\n",
            "On-chip memory remaining for caching model parameters: 6.05MiB\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/small_dense_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "FULLY_CONNECTED                1          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/big_dense_int8.tflite\n",
            "Input size: 64.84KiB\n",
            "Output model: /content/Edge_TPU-Models/big_dense_int8_edgetpu.tflite\n",
            "Output size: 112.62KiB\n",
            "On-chip memory used for caching model parameters: 64.00KiB\n",
            "On-chip memory remaining for caching model parameters: 6.05MiB\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/big_dense_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "FULLY_CONNECTED                1          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/simple_conv2d_int8.tflite\n",
            "Input size: 1.66KiB\n",
            "Output model: /content/Edge_TPU-Models/simple_conv2d_int8_edgetpu.tflite\n",
            "Output size: 1.44KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 0\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/simple_conv2d_int8_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 0\n",
            "Number of operations that will run on CPU: 1\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        1          Tensor has unsupported rank (up to 3 innermost dimensions mapped)\n",
            "\n",
            "Input model: /content/TF_Lite-Models/dilated_conv2d_int8.tflite\n",
            "Input size: 1.69KiB\n",
            "Output model: /content/Edge_TPU-Models/dilated_conv2d_int8_edgetpu.tflite\n",
            "Output size: 1.46KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 0\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/dilated_conv2d_int8_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 0\n",
            "Number of operations that will run on CPU: 1\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        1          Tensor has unsupported rank (up to 3 innermost dimensions mapped)\n",
            "\n",
            "Input model: /content/TF_Lite-Models/strided_conv2d_int8.tflite\n",
            "Input size: 1.67KiB\n",
            "Output model: /content/Edge_TPU-Models/strided_conv2d_int8_edgetpu.tflite\n",
            "Output size: 1.45KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 0\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/strided_conv2d_int8_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 0\n",
            "Number of operations that will run on CPU: 1\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        1          Tensor has unsupported rank (up to 3 innermost dimensions mapped)\n",
            "\n",
            "Input model: /content/TF_Lite-Models/big_conv2d_int8.tflite\n",
            "Input size: 2.55KiB\n",
            "Output model: /content/Edge_TPU-Models/big_conv2d_int8_edgetpu.tflite\n",
            "Output size: 2.34KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 0\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/big_conv2d_int8_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 0\n",
            "Number of operations that will run on CPU: 1\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        1          Tensor has unsupported rank (up to 3 innermost dimensions mapped)\n",
            "\n",
            "Input model: /content/TF_Lite-Models/small_conv2d_int8.tflite\n",
            "Input size: 1.50KiB\n",
            "Output model: /content/Edge_TPU-Models/small_conv2d_int8_edgetpu.tflite\n",
            "Output size: 1.28KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 0\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/small_conv2d_int8_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 0\n",
            "Number of operations that will run on CPU: 1\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        1          Tensor has unsupported rank (up to 3 innermost dimensions mapped)\n",
            "\n",
            "Input model: /content/TF_Lite-Models/many_conv2d_int8.tflite\n",
            "Input size: 14.77KiB\n",
            "Output model: /content/Edge_TPU-Models/many_conv2d_int8_edgetpu.tflite\n",
            "Output size: 14.54KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 0\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/many_conv2d_int8_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 0\n",
            "Number of operations that will run on CPU: 1\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        1          Tensor has unsupported rank (up to 3 innermost dimensions mapped)\n",
            "\n",
            "Input model: /content/TF_Lite-Models/few_conv2d_int8.tflite\n",
            "Input size: 1.18KiB\n",
            "Output model: /content/Edge_TPU-Models/few_conv2d_int8_edgetpu.tflite\n",
            "Output size: 984.00B\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 0\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/few_conv2d_int8_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 0\n",
            "Number of operations that will run on CPU: 1\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        1          Tensor has unsupported rank (up to 3 innermost dimensions mapped)\n",
            "Compilation child process completed within timeout period.\n",
            "Compilation succeeded! \n",
            "\n"
          ]
        }
      ],
      "source": [
        "if not os.path.isdir(\"Edge_TPU-Models\"): os.mkdir(\"Edge_TPU-Models\")\n",
        "\n",
        "filenames = \"\"\n",
        "for model in models:\n",
        "  filenames += \" \"+current_dir+\"/TF_Lite-Models/\"+model.name+\"_int8.tflite\"\n",
        "result = subprocess.run(['edgetpu_compiler','-s','-o',\n",
        "                         current_dir+'/Edge_TPU-Models',*filenames.split()],\n",
        "                        stdout=subprocess.PIPE)\n",
        "print(result.stdout.decode('ascii'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "ai_hardware_accelerators_colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
