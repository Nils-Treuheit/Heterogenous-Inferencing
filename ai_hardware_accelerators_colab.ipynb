{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDplXLeYwNNy"
      },
      "source": [
        "#Create Simple Tensorflow Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4ghjtz04EoA-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os, subprocess, copy\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "BatchSize = 1 #512\n",
        "picture_shape = (128,128,3)\n",
        "linear_data_shape = (128)\n",
        "pictures = tf.keras.Input(shape=picture_shape, batch_size=BatchSize)\n",
        "linear_data = tf.keras.Input(shape=linear_data_shape, batch_size=BatchSize)\n",
        "models = []\n",
        "\n",
        "\n",
        "# relu activation model\n",
        "out = tf.keras.layers.Activation('relu')(linear_data)\n",
        "relu_act = tf.keras.Model(inputs=linear_data,\n",
        "                          outputs=out,\n",
        "                          name=\"relu_act\")\n",
        "models.append(relu_act)\n",
        "for _ in range(2):\n",
        "  out = tf.keras.layers.Activation('relu')(out)\n",
        "models.append(tf.keras.Model(inputs=linear_data,\n",
        "                             outputs=out,\n",
        "                             name=\"relu_act_stacked3\"))\n",
        "for _ in range(5):\n",
        "  out = tf.keras.layers.Activation('relu')(out)\n",
        "models.append(tf.keras.Model(inputs=linear_data,\n",
        "                             outputs=out,\n",
        "                             name=\"relu_act_stacked8\"))\n",
        "\n",
        "# leaky relu activation model\n",
        "out = tf.keras.layers.LeakyReLU()(linear_data)\n",
        "leaky_relu_act = tf.keras.Model(inputs=linear_data,\n",
        "                                outputs=out,\n",
        "                                name=\"leaky_relu_act\")\n",
        "models.append(leaky_relu_act)\n",
        "for _ in range(2):\n",
        "  out = tf.keras.layers.LeakyReLU()(out)\n",
        "models.append(tf.keras.Model(inputs=linear_data,\n",
        "                             outputs=out,\n",
        "                             name=\"leaky_relu_act_stacked3\"))\n",
        "for _ in range(5):\n",
        "  out = tf.keras.layers.LeakyReLU()(out)\n",
        "models.append(tf.keras.Model(inputs=linear_data,\n",
        "                             outputs=out,\n",
        "                             name=\"leaky_relu_act_stacked8\"))\n",
        "\n",
        "\n",
        "# tanh activation model\n",
        "out = tf.keras.layers.Activation('tanh')(linear_data)\n",
        "tanh_act = tf.keras.Model(inputs=linear_data,\n",
        "                          outputs=out,\n",
        "                          name=\"tanh_act\")\n",
        "models.append(tanh_act)\n",
        "for _ in range(2):\n",
        "  out = tf.keras.layers.Activation('tanh')(out)\n",
        "models.append(tf.keras.Model(inputs=linear_data,\n",
        "                             outputs=out,\n",
        "                             name=\"tanh_act_stacked3\"))\n",
        "for _ in range(5):\n",
        "  out = tf.keras.layers.Activation('tanh')(out)\n",
        "models.append(tf.keras.Model(inputs=linear_data,\n",
        "                             outputs=out,\n",
        "                             name=\"tanh_act_stacked8\"))\n",
        "\n",
        "\n",
        "# sigmoid activation model\n",
        "out = tf.keras.layers.Activation('sigmoid')(linear_data)\n",
        "sigmoid_act = tf.keras.Model(inputs=linear_data,\n",
        "                             outputs=out,\n",
        "                             name=\"sigmoid_act\")\n",
        "models.append(sigmoid_act)\n",
        "for _ in range(2):\n",
        "  out = tf.keras.layers.Activation('sigmoid')(out)\n",
        "models.append(tf.keras.Model(inputs=linear_data,\n",
        "                             outputs=out,\n",
        "                             name=\"sigmoid_act_stacked3\"))\n",
        "for _ in range(5):\n",
        "  out = tf.keras.layers.Activation('sigmoid')(out)\n",
        "models.append(tf.keras.Model(inputs=linear_data,\n",
        "                             outputs=out,\n",
        "                             name=\"sigmoid_act_stacked8\"))\n",
        "\n",
        "# scalar_multiply model\n",
        "out = tf.keras.layers.Lambda(lambda x: x * 5.0)(linear_data)\n",
        "scalar_mult = tf.keras.Model(inputs=linear_data,\n",
        "                             outputs=out,\n",
        "                             name=\"scalar_mult\")\n",
        "models.append(scalar_mult)\n",
        "for _ in range(2):\n",
        "  out = tf.keras.layers.Lambda(lambda x: x * 5.0)(out)\n",
        "models.append(tf.keras.Model(inputs=linear_data,\n",
        "                             outputs=out,\n",
        "                             name=\"scalar_mult_stacked3\"))\n",
        "for _ in range(5):\n",
        "  out = tf.keras.layers.Lambda(lambda x: x * 5.0)(out)\n",
        "models.append(tf.keras.Model(inputs=linear_data,\n",
        "                             outputs=out,\n",
        "                             name=\"scalar_mult_stacked8\"))\n",
        "\n",
        "# small dense model\n",
        "out = tf.keras.layers.Dense(8)(linear_data)\n",
        "small_dense = tf.keras.Model(inputs=linear_data,\n",
        "                             outputs=out,\n",
        "                             name=\"small_dense\")\n",
        "models.append(small_dense)\n",
        "for _ in range(2):\n",
        "  out = tf.keras.layers.Dense(8)(out)\n",
        "models.append(tf.keras.Model(inputs=linear_data,\n",
        "                             outputs=out,\n",
        "                             name=\"small_dense_stacked3\"))\n",
        "for _ in range(5):\n",
        "  out = tf.keras.layers.Dense(8)(out)\n",
        "models.append(tf.keras.Model(inputs=linear_data,\n",
        "                             outputs=out,\n",
        "                             name=\"small_dense_stacked8\"))\n",
        "\n",
        "# big dense model\n",
        "out = tf.keras.layers.Dense(512)(linear_data)\n",
        "big_dense = tf.keras.Model(inputs=linear_data,\n",
        "                           outputs=out,\n",
        "                           name=\"big_dense\")\n",
        "models.append(big_dense)\n",
        "for _ in range(2):\n",
        "  out = tf.keras.layers.Dense(512)(out)\n",
        "models.append(tf.keras.Model(inputs=linear_data,\n",
        "                             outputs=out,\n",
        "                             name=\"big_dense_stacked3\"))\n",
        "for _ in range(5):\n",
        "  out = tf.keras.layers.Dense(512)(out)\n",
        "models.append(tf.keras.Model(inputs=linear_data,\n",
        "                             outputs=out,\n",
        "                             name=\"big_dense_stacked8\"))\n",
        "\n",
        "# simple conv2d model\n",
        "out = tf.keras.layers.Conv2D(12,3)(pictures)\n",
        "simple_conv2d = tf.keras.Model(inputs=pictures,\n",
        "                               outputs=out,\n",
        "                               name=\"simple_conv2d\")\n",
        "models.append(simple_conv2d)\n",
        "for _ in range(2):\n",
        "  out = tf.keras.layers.Conv2D(12,3)(out)\n",
        "models.append(tf.keras.Model(inputs=pictures,\n",
        "                             outputs=out,\n",
        "                             name=\"simple_conv2d_stacked3\"))\n",
        "for _ in range(5):\n",
        "  out = tf.keras.layers.Conv2D(12,3)(out)\n",
        "models.append(tf.keras.Model(inputs=pictures,\n",
        "                             outputs=out,\n",
        "                             name=\"simple_conv2d_stacked8\"))\n",
        "\n",
        "# dilated conv2d model\n",
        "out = tf.keras.layers.Conv2D(12,3,dilation_rate=2)(pictures)\n",
        "dilated_conv2d = tf.keras.Model(inputs=pictures,\n",
        "                                outputs=out,\n",
        "                                name=\"dilated_conv2d\")\n",
        "models.append(dilated_conv2d)\n",
        "for _ in range(2):\n",
        "  out = tf.keras.layers.Conv2D(12,3,dilation_rate=2)(out)\n",
        "models.append(tf.keras.Model(inputs=pictures,\n",
        "                             outputs=out,\n",
        "                             name=\"dilated_conv2d_stacked3\"))\n",
        "for _ in range(5):\n",
        "  out = tf.keras.layers.Conv2D(12,3,dilation_rate=2)(out)\n",
        "models.append(tf.keras.Model(inputs=pictures,\n",
        "                             outputs=out,\n",
        "                             name=\"dilated_conv2d_stacked8\"))\n",
        "\n",
        "# strided conv2d model\n",
        "out = tf.keras.layers.Conv2D(12,3,strides=5)(pictures)\n",
        "strided_conv2d = tf.keras.Model(inputs=pictures,\n",
        "                                outputs=out,\n",
        "                                name=\"strided_conv2d\")\n",
        "models.append(strided_conv2d)\n",
        "for _ in range(2):\n",
        "  out = tf.keras.layers.Conv2D(12,3,strides=5)(out)\n",
        "models.append(tf.keras.Model(inputs=pictures,\n",
        "                             outputs=out,\n",
        "                             name=\"strided_conv2d_stacked3\"))\n",
        "\n",
        "# big conv2d model\n",
        "out = tf.keras.layers.Conv2D(9,7)(pictures)\n",
        "big_conv2d = tf.keras.Model(inputs=pictures,\n",
        "                            outputs=out,\n",
        "                            name=\"big_conv2d\")\n",
        "models.append(big_conv2d)\n",
        "for _ in range(2):\n",
        "  out = tf.keras.layers.Conv2D(9,7)(out)\n",
        "models.append(tf.keras.Model(inputs=pictures,\n",
        "                             outputs=out,\n",
        "                             name=\"big_conv2d_stacked3\"))\n",
        "for _ in range(5):\n",
        "  out = tf.keras.layers.Conv2D(9,7)(out)\n",
        "models.append(tf.keras.Model(inputs=pictures,\n",
        "                             outputs=out,\n",
        "                             name=\"big_conv2d_stacked8\"))\n",
        "\n",
        "# small conv2d model\n",
        "out = tf.keras.layers.Conv2D(9,3)(pictures)\n",
        "small_conv2d = tf.keras.Model(inputs=pictures,\n",
        "                              outputs=out,\n",
        "                              name=\"small_conv2d\")\n",
        "models.append(small_conv2d)\n",
        "for _ in range(2):\n",
        "  out = tf.keras.layers.Conv2D(9,3)(out)\n",
        "models.append(tf.keras.Model(inputs=pictures,\n",
        "                             outputs=out,\n",
        "                             name=\"small_conv2d_stacked3\"))\n",
        "for _ in range(5):\n",
        "  out = tf.keras.layers.Conv2D(9,3)(out)\n",
        "models.append(tf.keras.Model(inputs=pictures,\n",
        "                             outputs=out,\n",
        "                             name=\"small_conv2d_stacked8\"))\n",
        "\n",
        "# many conv2d model\n",
        "out = tf.keras.layers.Conv2D(256,3)(pictures)\n",
        "many_conv2d = tf.keras.Model(inputs=pictures,\n",
        "                             outputs=out,\n",
        "                             name=\"many_conv2d\")\n",
        "models.append(many_conv2d)\n",
        "for _ in range(2):\n",
        "  out = tf.keras.layers.Conv2D(256,3)(out)\n",
        "models.append(tf.keras.Model(inputs=pictures,\n",
        "                             outputs=out,\n",
        "                             name=\"many_conv2d_stacked3\"))\n",
        "for _ in range(5):\n",
        "  out = tf.keras.layers.Conv2D(256,3)(out)\n",
        "models.append(tf.keras.Model(inputs=pictures,\n",
        "                             outputs=out,\n",
        "                             name=\"many_conv2d_stacked8\"))\n",
        "\n",
        "# few conv2d model\n",
        "out = tf.keras.layers.Conv2D(3,3)(pictures)\n",
        "few_conv2d = tf.keras.Model(inputs=pictures,\n",
        "                            outputs=out,\n",
        "                            name=\"few_conv2d\")\n",
        "models.append(few_conv2d)\n",
        "for _ in range(2):\n",
        "  out = tf.keras.layers.Conv2D(3,3)(out)\n",
        "models.append(tf.keras.Model(inputs=pictures,\n",
        "                             outputs=out,\n",
        "                             name=\"few_conv2d_stacked3\"))\n",
        "for _ in range(5):\n",
        "  out = tf.keras.layers.Conv2D(3,3)(out)\n",
        "models.append(tf.keras.Model(inputs=pictures,\n",
        "                             outputs=out,\n",
        "                             name=\"few_conv2d_stacked8\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgdK_wQaRpkx",
        "outputId": "3d4d574f-945d-462f-b7d0-740485ba7987"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"relu_act\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(1, 128)]                0         \n",
            "                                                                 \n",
            " activation (Activation)     (1, 128)                  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "relu_act.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDsrYzaTSNUf",
        "outputId": "a16ee52d-7ecd-4898-ee4f-b85164af4538"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"leaky_relu_act\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(1, 128)]                0         \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (1, 128)                  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "leaky_relu_act.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LIizkI2SShh",
        "outputId": "1729e2cf-ca8e-435c-fb55-0dafb564ae10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tanh_act\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(1, 128)]                0         \n",
            "                                                                 \n",
            " activation_8 (Activation)   (1, 128)                  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "tanh_act.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjPUgCUVSYPT",
        "outputId": "fd080041-3dda-440a-b931-8dfa3c56a648"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sigmoid_act\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(1, 128)]                0         \n",
            "                                                                 \n",
            " activation_16 (Activation)  (1, 128)                  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "sigmoid_act.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdvQuGWvSbsm",
        "outputId": "61a422a2-af95-4c65-bd94-d7177498d0b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"scalar_mult\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(1, 128)]                0         \n",
            "                                                                 \n",
            " lambda (Lambda)             (1, 128)                  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "scalar_mult.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeKOcyyrSqJg",
        "outputId": "0cc0db7b-c4fb-4de1-91a1-0b9b1615ecda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"small_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(1, 128)]                0         \n",
            "                                                                 \n",
            " dense (Dense)               (1, 8)                    1032      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,032\n",
            "Trainable params: 1,032\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "small_dense.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANDbMUZISt14",
        "outputId": "f7fb8c89-6361-4c80-d379-5460deb77aad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"big_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(1, 128)]                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (1, 512)                  66048     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66,048\n",
            "Trainable params: 66,048\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "big_dense.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPqQH5zoS0zI",
        "outputId": "c9bcdf23-2901-4db4-a2f7-e7f5404edd93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"simple_conv2d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(1, 128, 128, 3)]        0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (1, 126, 126, 12)         336       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 336\n",
            "Trainable params: 336\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "simple_conv2d.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjZdM_V3TCHw",
        "outputId": "05778da3-1cd3-42c8-979a-c4d92d4ed8cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"strided_conv2d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(1, 128, 128, 3)]        0         \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (1, 26, 26, 12)           336       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 336\n",
            "Trainable params: 336\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "strided_conv2d.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ94bUPnTIpV",
        "outputId": "c4a3f264-2120-454f-c4a7-ba3762a63857"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"dilated_conv2d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(1, 128, 128, 3)]        0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (1, 124, 124, 12)         336       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 336\n",
            "Trainable params: 336\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "dilated_conv2d.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUgEY74jTMMQ",
        "outputId": "4ffb9013-a2da-44c1-effe-cc0d11341d87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"small_conv2d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(1, 128, 128, 3)]        0         \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (1, 126, 126, 9)          252       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 252\n",
            "Trainable params: 252\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "small_conv2d.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi_su7zlTR03",
        "outputId": "f48dd012-5abd-448a-af2f-f0d859ad7191"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"big_conv2d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(1, 128, 128, 3)]        0         \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (1, 122, 122, 9)          1332      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,332\n",
            "Trainable params: 1,332\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "big_conv2d.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtOgM2c4nfLl",
        "outputId": "f12402f0-3965-4260-e882-edbe0c18f2ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"few_conv2d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(1, 128, 128, 3)]        0         \n",
            "                                                                 \n",
            " conv2d_43 (Conv2D)          (1, 126, 126, 3)          84        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 84\n",
            "Trainable params: 84\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "few_conv2d.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv_9L3KHnkrn",
        "outputId": "a7e24748-f0d3-420b-fd3b-bec3fcd07e07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"many_conv2d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(1, 128, 128, 3)]        0         \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (1, 126, 126, 256)        7168      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,168\n",
            "Trainable params: 7,168\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "many_conv2d.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models[7].summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8ck0Vkh1CU-",
        "outputId": "de61c764-4c9f-49a1-9133-f1c4aaf09841"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tanh_act_stacked3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(1, 128)]                0         \n",
            "                                                                 \n",
            " activation_8 (Activation)   (1, 128)                  0         \n",
            "                                                                 \n",
            " activation_9 (Activation)   (1, 128)                  0         \n",
            "                                                                 \n",
            " activation_10 (Activation)  (1, 128)                  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models[8].summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skvFzfYA1FpO",
        "outputId": "93b678d2-c38c-448d-c7ac-63f73d13a2e7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tanh_act_stacked8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(1, 128)]                0         \n",
            "                                                                 \n",
            " activation_8 (Activation)   (1, 128)                  0         \n",
            "                                                                 \n",
            " activation_9 (Activation)   (1, 128)                  0         \n",
            "                                                                 \n",
            " activation_10 (Activation)  (1, 128)                  0         \n",
            "                                                                 \n",
            " activation_11 (Activation)  (1, 128)                  0         \n",
            "                                                                 \n",
            " activation_12 (Activation)  (1, 128)                  0         \n",
            "                                                                 \n",
            " activation_13 (Activation)  (1, 128)                  0         \n",
            "                                                                 \n",
            " activation_14 (Activation)  (1, 128)                  0         \n",
            "                                                                 \n",
            " activation_15 (Activation)  (1, 128)                  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models[16].summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo5ck8qO1HdV",
        "outputId": "818f4c08-56e3-4205-a5a5-d63e8e9b2e8e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"small_dense_stacked3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(1, 128)]                0         \n",
            "                                                                 \n",
            " dense (Dense)               (1, 8)                    1032      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (1, 8)                    72        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (1, 8)                    72        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,176\n",
            "Trainable params: 1,176\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models[17].summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cwl9Uh9p1J1l",
        "outputId": "388f9923-32f7-49e3-bb8c-9cb07822e343"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"small_dense_stacked8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(1, 128)]                0         \n",
            "                                                                 \n",
            " dense (Dense)               (1, 8)                    1032      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (1, 8)                    72        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (1, 8)                    72        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (1, 8)                    72        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (1, 8)                    72        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (1, 8)                    72        \n",
            "                                                                 \n",
            " dense_6 (Dense)             (1, 8)                    72        \n",
            "                                                                 \n",
            " dense_7 (Dense)             (1, 8)                    72        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,536\n",
            "Trainable params: 1,536\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models[28].summary()"
      ],
      "metadata": {
        "id": "IvVji8QqDGYg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4046cced-ca01-4245-89ab-54470b27f448"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"strided_conv2d_stacked3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(1, 128, 128, 3)]        0         \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (1, 26, 26, 12)           336       \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (1, 5, 5, 12)             1308      \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (1, 1, 1, 12)             1308      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,952\n",
            "Trainable params: 2,952\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models[30].summary()"
      ],
      "metadata": {
        "id": "7i7BPn6nDHea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07acebe3-4eef-4adb-942b-52f6a818b739"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"big_conv2d_stacked3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(1, 128, 128, 3)]        0         \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (1, 122, 122, 9)          1332      \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (1, 116, 116, 9)          3978      \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (1, 110, 110, 9)          3978      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,288\n",
            "Trainable params: 9,288\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models[31].summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K71ksgFr1TdV",
        "outputId": "f28d0ce2-b7d0-4f8b-e425-ab7503c97fae"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"big_conv2d_stacked8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(1, 128, 128, 3)]        0         \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (1, 122, 122, 9)          1332      \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (1, 116, 116, 9)          3978      \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (1, 110, 110, 9)          3978      \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (1, 104, 104, 9)          3978      \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (1, 98, 98, 9)            3978      \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (1, 92, 92, 9)            3978      \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (1, 86, 86, 9)            3978      \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (1, 80, 80, 9)            3978      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29,178\n",
            "Trainable params: 29,178\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BztcZHgsDAbH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ_1pEovIYsf"
      },
      "source": [
        "#Convert and Store TF-Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVjJhvHnIZWK",
        "outputId": "6ce17763-e6b3-4b42-b606-2ecc774ceb3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/relu_act/assets\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp52u1svqc/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/relu_act_stacked3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/relu_act_stacked3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpvsyf4jzw/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpvsyf4jzw/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/relu_act_stacked8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/relu_act_stacked8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpgcf4_5ms/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpgcf4_5ms/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/leaky_relu_act/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/leaky_relu_act/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpjbrxcbq0/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpjbrxcbq0/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/leaky_relu_act_stacked3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/leaky_relu_act_stacked3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpixwn6bxi/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpixwn6bxi/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/leaky_relu_act_stacked8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/leaky_relu_act_stacked8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp4tjgri3t/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp4tjgri3t/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/tanh_act/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/tanh_act/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp0syes4xh/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp0syes4xh/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/tanh_act_stacked3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/tanh_act_stacked3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpq1yd8qvg/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpq1yd8qvg/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/tanh_act_stacked8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/tanh_act_stacked8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpml4xzhy9/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpml4xzhy9/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/sigmoid_act/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/sigmoid_act/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp3hjfx4s5/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp3hjfx4s5/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/sigmoid_act_stacked3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/sigmoid_act_stacked3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp9vuubjom/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp9vuubjom/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/sigmoid_act_stacked8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/sigmoid_act_stacked8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp5t6h7v9p/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp5t6h7v9p/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/scalar_mult/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/scalar_mult/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpbaa4a6v1/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpbaa4a6v1/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/scalar_mult_stacked3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/scalar_mult_stacked3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp55kx1zz8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp55kx1zz8/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/scalar_mult_stacked8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/scalar_mult_stacked8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp9i3ezpqw/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp9i3ezpqw/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/small_dense/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/small_dense/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpeytjvd8x/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpeytjvd8x/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/small_dense_stacked3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/small_dense_stacked3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpc3aquinu/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpc3aquinu/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/small_dense_stacked8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/small_dense_stacked8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmps7sv0a9z/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmps7sv0a9z/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/big_dense/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/big_dense/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpspyosv03/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpspyosv03/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/big_dense_stacked3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/big_dense_stacked3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpqj0icssm/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpqj0icssm/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/big_dense_stacked8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/big_dense_stacked8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpdohnrsfb/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpdohnrsfb/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/simple_conv2d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/simple_conv2d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp8uroholn/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp8uroholn/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/simple_conv2d_stacked3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/simple_conv2d_stacked3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp7v9388zx/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp7v9388zx/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/simple_conv2d_stacked8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/simple_conv2d_stacked8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp17b0zbrp/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp17b0zbrp/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/dilated_conv2d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/dilated_conv2d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp0v3husu8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp0v3husu8/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/dilated_conv2d_stacked3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/dilated_conv2d_stacked3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp78jtz7b3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp78jtz7b3/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/dilated_conv2d_stacked8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/dilated_conv2d_stacked8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmprs56pljr/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmprs56pljr/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/strided_conv2d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/strided_conv2d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpng7abepq/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpng7abepq/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/strided_conv2d_stacked3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/strided_conv2d_stacked3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpn5tz7jqa/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpn5tz7jqa/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/big_conv2d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/big_conv2d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpetp44d8l/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpetp44d8l/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/big_conv2d_stacked3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/big_conv2d_stacked3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp0xv52gus/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp0xv52gus/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/big_conv2d_stacked8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/big_conv2d_stacked8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmphs464juk/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmphs464juk/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/small_conv2d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/small_conv2d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpiee3z40f/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpiee3z40f/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/small_conv2d_stacked3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/small_conv2d_stacked3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpt5bjeva0/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpt5bjeva0/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/small_conv2d_stacked8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/small_conv2d_stacked8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpo7yznpaw/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpo7yznpaw/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/many_conv2d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/many_conv2d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpmwlqe7w_/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpmwlqe7w_/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/many_conv2d_stacked3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/many_conv2d_stacked3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpt4e97cba/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpt4e97cba/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/many_conv2d_stacked8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/many_conv2d_stacked8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpvop3fsri/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpvop3fsri/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/few_conv2d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/few_conv2d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpomwuv2v9/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpomwuv2v9/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/few_conv2d_stacked3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/few_conv2d_stacked3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpcbc_oq4c/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpcbc_oq4c/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/few_conv2d_stacked8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: Tensor_Flow-Models/few_conv2d_stacked8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp41bpu__6/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp41bpu__6/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "relu_act\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp3rsmacfm/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp3rsmacfm/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "relu_act_stacked3\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp3k16fnbt/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp3k16fnbt/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "relu_act_stacked8\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpssmunrsc/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpssmunrsc/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "leaky_relu_act\n",
            "INFO:tensorflow:Assets written to: /tmp/tmppxzrqt41/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmppxzrqt41/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "leaky_relu_act_stacked3\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpcrwiagm6/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpcrwiagm6/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "leaky_relu_act_stacked8\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpq8zn_vbm/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpq8zn_vbm/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tanh_act\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpwfhrjax7/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpwfhrjax7/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tanh_act_stacked3\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpgg3ao9yn/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpgg3ao9yn/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tanh_act_stacked8\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp9b3r850a/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp9b3r850a/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sigmoid_act\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpo7vz9v7v/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpo7vz9v7v/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sigmoid_act_stacked3\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpf7w5fxv5/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpf7w5fxv5/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sigmoid_act_stacked8\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp6mkqhq4b/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp6mkqhq4b/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scalar_mult\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpvtylf5fw/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpvtylf5fw/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scalar_mult_stacked3\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpmkifnw3t/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpmkifnw3t/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scalar_mult_stacked8\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpjyr3cay_/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpjyr3cay_/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "small_dense\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpcdgx3hgl/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpcdgx3hgl/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "small_dense_stacked3\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp4dmokcst/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp4dmokcst/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "small_dense_stacked8\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpqov_644g/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpqov_644g/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "big_dense\n",
            "INFO:tensorflow:Assets written to: /tmp/tmppxsehejc/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmppxsehejc/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "big_dense_stacked3\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpk643yera/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpk643yera/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "big_dense_stacked8\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpjdik47os/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpjdik47os/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "simple_conv2d\n",
            "INFO:tensorflow:Assets written to: /tmp/tmprr5z2ppg/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmprr5z2ppg/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "simple_conv2d_stacked3\n",
            "INFO:tensorflow:Assets written to: /tmp/tmps8hv4w9e/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmps8hv4w9e/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "simple_conv2d_stacked8\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpm71oh2s8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpm71oh2s8/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dilated_conv2d\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpgghg79v5/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpgghg79v5/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dilated_conv2d_stacked3\n",
            "INFO:tensorflow:Assets written to: /tmp/tmph2k_rlt2/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmph2k_rlt2/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dilated_conv2d_stacked8\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp2_3opgjz/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp2_3opgjz/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "strided_conv2d\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpqovo2ufq/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpqovo2ufq/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "strided_conv2d_stacked3\n",
            "INFO:tensorflow:Assets written to: /tmp/tmppebldigg/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmppebldigg/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "big_conv2d\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpbf5w6acu/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpbf5w6acu/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "big_conv2d_stacked3\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpr0gnsaap/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpr0gnsaap/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "big_conv2d_stacked8\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpf1946uql/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpf1946uql/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "small_conv2d\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpil9dhydc/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpil9dhydc/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "small_conv2d_stacked3\n",
            "INFO:tensorflow:Assets written to: /tmp/tmphnieuj2w/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmphnieuj2w/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "small_conv2d_stacked8\n",
            "INFO:tensorflow:Assets written to: /tmp/tmptqp2w7q_/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmptqp2w7q_/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "many_conv2d\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp9uq4ke0c/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp9uq4ke0c/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "many_conv2d_stacked3\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpn2ygvch4/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpn2ygvch4/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "many_conv2d_stacked8\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpbbiivafa/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpbbiivafa/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "few_conv2d\n",
            "INFO:tensorflow:Assets written to: /tmp/tmppgmmgwim/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmppgmmgwim/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "few_conv2d_stacked3\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpun40jw5j/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpun40jw5j/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "few_conv2d_stacked8\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp0cpg06qq/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp0cpg06qq/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ],
      "source": [
        "if not os.path.isdir(\"TF_Lite-Models\"): os.mkdir(\"TF_Lite-Models\")\n",
        "if not os.path.isdir(\"Tensor_Flow-Models\"): os.mkdir(\"Tensor_Flow-Models\")\n",
        "for model in models:\n",
        "  model.save((\"Tensor_Flow-Models/\"+model.name))\n",
        "  with open((\"TF_Lite-Models/\"+model.name+\".tflite\"), 'wb') as model_file:\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    tflite_model = converter.convert()\n",
        "    model_file.write(tflite_model)\n",
        "for model in models:\n",
        "  print(model.name)\n",
        "  with open((\"TF_Lite-Models/\"+model.name+\"_int8.tflite\"), 'wb') as model_file:\n",
        "    tmp_shape=model.get_layer(index=0).input_shape[0]\n",
        "    data_gen=lambda : (yield [tf.random.uniform(shape=tmp_shape,dtype=tf.dtypes.float32)])\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    converter.optimizations=[tf.lite.Optimize.DEFAULT]\n",
        "    converter.inference_input_type=tf.int8\n",
        "    converter.inference_output_type=tf.int8\n",
        "    converter.target_spec.supported_ops=[tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "    converter.representative_dataset=data_gen\n",
        "    tflite_model = converter.convert()\n",
        "    model_file.write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFoqrBB_Ehxb"
      },
      "source": [
        "#Compile Models for OpenVINO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GV2wp6rpl94p",
        "outputId": "13a795af-bbbf-477d-ce0e-c178efa77078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-18 21:06:07--  https://apt.repos.intel.com/openvino/2021/GPG-PUB-KEY-INTEL-OPENVINO-2021\n",
            "Resolving apt.repos.intel.com (apt.repos.intel.com)... 104.78.245.72, 2600:1407:3c00:1493::4b23, 2600:1407:3c00:148c::4b23\n",
            "Connecting to apt.repos.intel.com (apt.repos.intel.com)|104.78.245.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 939 [binary/octet-stream]\n",
            "Saving to: ‘GPG-PUB-KEY-INTEL-OPENVINO-2021.1’\n",
            "\n",
            "\r          GPG-PUB-K   0%[                    ]       0  --.-KB/s               \rGPG-PUB-KEY-INTEL-O 100%[===================>]     939  --.-KB/s    in 0s      \n",
            "\n",
            "2022-03-18 21:06:07 (109 MB/s) - ‘GPG-PUB-KEY-INTEL-OPENVINO-2021.1’ saved [939/939]\n",
            "\n",
            "OK\n",
            "deb https://apt.repos.intel.com/openvino/2021 all main\n",
            "[setupvars.sh] OpenVINO environment initialized\n",
            "Requirement already satisfied: openvino-dev in /usr/local/lib/python3.7/dist-packages (2021.4.2)\n",
            "Requirement already satisfied: progress>=1.5 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (1.6)\n",
            "Requirement already satisfied: rawpy>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (0.17.0)\n",
            "Requirement already satisfied: sentencepiece>=0.1.95 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (0.1.96)\n",
            "Requirement already satisfied: addict>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (2.4.0)\n",
            "Requirement already satisfied: opencv-python==4.5.* in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (4.5.5.64)\n",
            "Requirement already satisfied: tokenizers>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (0.11.6)\n",
            "Requirement already satisfied: texttable~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (1.6.4)\n",
            "Requirement already satisfied: nltk>=3.5 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (3.7)\n",
            "Requirement already satisfied: openvino==2021.4.2 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (2021.4.2)\n",
            "Requirement already satisfied: yamlloader>=0.5 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (1.1.0)\n",
            "Requirement already satisfied: pandas~=1.1.5 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (1.1.5)\n",
            "Requirement already satisfied: jstyleson~=0.0.2 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (0.0.2)\n",
            "Requirement already satisfied: editdistance>=0.5.3 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (0.5.3)\n",
            "Requirement already satisfied: scikit-image>=0.17.2 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (0.18.3)\n",
            "Requirement already satisfied: nibabel>=3.2.1 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (3.2.2)\n",
            "Requirement already satisfied: scipy~=1.5.4 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (1.5.4)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (6.0)\n",
            "Requirement already satisfied: fast-ctc-decode>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (0.3.0)\n",
            "Requirement already satisfied: requests>=2.25.1 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (2.27.1)\n",
            "Requirement already satisfied: networkx~=2.5 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (2.6.3)\n",
            "Requirement already satisfied: pydicom>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.54.1 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (4.63.0)\n",
            "Requirement already satisfied: pillow>=8.1.2 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (9.0.1)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (0.7.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (1.0.2)\n",
            "Requirement already satisfied: numpy<1.20,>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (1.19.5)\n",
            "Requirement already satisfied: shapely>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (1.8.1.post1)\n",
            "Requirement already satisfied: parasail>=1.2.4 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (1.2.4)\n",
            "Requirement already satisfied: py-cpuinfo>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (8.0.0)\n",
            "Requirement already satisfied: hyperopt~=0.1.2 in /usr/local/lib/python3.7/dist-packages (from openvino-dev) (0.1.2)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt~=0.1.2->openvino-dev) (4.0.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt~=0.1.2->openvino-dev) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hyperopt~=0.1.2->openvino-dev) (1.15.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from nibabel>=3.2.1->openvino-dev) (21.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from nibabel>=3.2.1->openvino-dev) (57.4.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.5->openvino-dev) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.5->openvino-dev) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.5->openvino-dev) (2022.3.15)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->nibabel>=3.2.1->openvino-dev) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas~=1.1.5->openvino-dev) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas~=1.1.5->openvino-dev) (2018.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->openvino-dev) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->openvino-dev) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->openvino-dev) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->openvino-dev) (1.24.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2->openvino-dev) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2->openvino-dev) (1.2.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2->openvino-dev) (2.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2->openvino-dev) (2021.11.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17.2->openvino-dev) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17.2->openvino-dev) (0.11.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.1->openvino-dev) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!wget https://apt.repos.intel.com/openvino/2021/GPG-PUB-KEY-INTEL-OPENVINO-2021\n",
        "!sudo apt-key add GPG-PUB-KEY-INTEL-OPENVINO-2021\n",
        "!echo \"deb https://apt.repos.intel.com/openvino/2021 all main\" | sudo tee /etc/apt/sources.list.d/intel-openvino-2021.list\n",
        "!sudo apt update > /dev/null $2>&1\n",
        "!sudo apt install intel-openvino-dev-ubuntu20-2021.3.394 -y > /dev/null $2>&1\n",
        "!bash /opt/intel/openvino_2021/bin/setupvars.sh\n",
        "!python3 -m pip install openvino-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29vSSMp0EntP",
        "outputId": "0e615dff-979d-4252-8431-d6b539a31a7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \trelu_act\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \trelu_act_stacked3\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \trelu_act_stacked8\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tleaky_relu_act\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tleaky_relu_act_stacked3\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tleaky_relu_act_stacked8\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \ttanh_act\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \ttanh_act_stacked3\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \ttanh_act_stacked8\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tsigmoid_act\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tsigmoid_act_stacked3\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tsigmoid_act_stacked8\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tscalar_mult\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tscalar_mult_stacked3\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tscalar_mult_stacked8\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tsmall_dense\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tsmall_dense_stacked3\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tsmall_dense_stacked8\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tbig_dense\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tbig_dense_stacked3\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tbig_dense_stacked8\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tsimple_conv2d\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tsimple_conv2d_stacked3\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tsimple_conv2d_stacked8\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tdilated_conv2d\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tdilated_conv2d_stacked3\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tdilated_conv2d_stacked8\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tstrided_conv2d\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tstrided_conv2d_stacked3\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tbig_conv2d\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tbig_conv2d_stacked3\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tbig_conv2d_stacked8\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tsmall_conv2d\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tsmall_conv2d_stacked3\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tsmall_conv2d_stacked8\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tmany_conv2d\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tmany_conv2d_stacked3\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tmany_conv2d_stacked8\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tfew_conv2d\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tfew_conv2d_stacked3\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \tNone\n",
            "\t- Path for generated IR: \t/content/OpenVINO-Models\n",
            "\t- IR output name: \tfew_conv2d_stacked8\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \t1\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \t[(1, 128, 128, 3)]\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tNone\n",
            "\t- Reverse input channels: \tFalse\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tTrue\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
            "\t- Use the config file: \tNone\n",
            "\t- Inference Engine found in: \t/usr/local/lib/python3.7/dist-packages/openvino\n",
            "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if not os.path.isdir(\"OpenVINO-Models\"): os.mkdir(\"OpenVINO-Models\")\n",
        "for model in models:\n",
        "  result = subprocess.run(['python3', '-m', 'mo', '--framework', 'tf',\n",
        "                           '--progress', '--input_model_is_text',\n",
        "                           '--batch', str(BatchSize), '--input_shape',\n",
        "                           str(model.get_layer(index=0).input_shape),\n",
        "                           '--data_type=FP16', '--model_name', model.name, \n",
        "                           '--saved_model_dir', \n",
        "                           current_dir+'/Tensor_Flow-Models/'+model.name,\n",
        "                           '--output_dir', current_dir+'/OpenVINO-Models'],\n",
        "                          stdout=subprocess.PIPE)\n",
        "  print(result.stdout.decode('ascii'))                      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctTk4Hf8qp8q"
      },
      "source": [
        "#Compile Models for Edge TPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiRFwaK7mVyh",
        "outputId": "8843d5d9-2be1-432f-f96c-702abcb544fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2537  100  2537    0     0  51775      0 --:--:-- --:--:-- --:--:-- 51775\n",
            "OK\n",
            "deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\n",
            "Hit:1 https://packages.cloud.google.com/apt coral-edgetpu-stable InRelease\n",
            "Hit:2 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:8 https://apt.repos.intel.com/openvino/2021 all InRelease\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:15 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "edgetpu-compiler is already the newest version (16.0).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 63 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "!echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install edgetpu-compiler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhkBIlpWq76r",
        "outputId": "3fb806ad-4620-4d84-cfc2-2b11e94a7e70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edge TPU Compiler version 16.0.384591198\n",
            "Started a compilation timeout timer of 180 seconds.\n",
            "\n",
            "Models compiled successfully in 9204 ms.\n",
            "\n",
            "Input model: /content/TF_Lite-Models/relu_act_int8.tflite\n",
            "Input size: 712.00B\n",
            "Output model: /content/Edge_TPU-Models/relu_act_int8_edgetpu.tflite\n",
            "Output size: 20.59KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/relu_act_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "RELU                           1          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/relu_act_stacked3_int8.tflite\n",
            "Input size: 720.00B\n",
            "Output model: /content/Edge_TPU-Models/relu_act_stacked3_int8_edgetpu.tflite\n",
            "Output size: 20.59KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/relu_act_stacked3_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "RELU                           1          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/relu_act_stacked8_int8.tflite\n",
            "Input size: 720.00B\n",
            "Output model: /content/Edge_TPU-Models/relu_act_stacked8_int8_edgetpu.tflite\n",
            "Output size: 20.59KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/relu_act_stacked8_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "RELU                           1          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/leaky_relu_act_int8.tflite\n",
            "Input size: 736.00B\n",
            "Output model: /content/Edge_TPU-Models/leaky_relu_act_int8_edgetpu.tflite\n",
            "Output size: 496.00B\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 0\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/leaky_relu_act_int8_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 0\n",
            "Number of operations that will run on CPU: 1\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "LEAKY_RELU                     1          Operation not supported\n",
            "\n",
            "Input model: /content/TF_Lite-Models/leaky_relu_act_stacked3_int8.tflite\n",
            "Input size: 1.09KiB\n",
            "Output model: /content/Edge_TPU-Models/leaky_relu_act_stacked3_int8_edgetpu.tflite\n",
            "Output size: 848.00B\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 0\n",
            "Total number of operations: 3\n",
            "Operation log: /content/Edge_TPU-Models/leaky_relu_act_stacked3_int8_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 0\n",
            "Number of operations that will run on CPU: 3\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "LEAKY_RELU                     3          Operation not supported\n",
            "\n",
            "Input model: /content/TF_Lite-Models/leaky_relu_act_stacked8_int8.tflite\n",
            "Input size: 1.97KiB\n",
            "Output model: /content/Edge_TPU-Models/leaky_relu_act_stacked8_int8_edgetpu.tflite\n",
            "Output size: 1.66KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 0\n",
            "Total number of operations: 8\n",
            "Operation log: /content/Edge_TPU-Models/leaky_relu_act_stacked8_int8_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 0\n",
            "Number of operations that will run on CPU: 8\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "LEAKY_RELU                     8          Operation not supported\n",
            "\n",
            "Input model: /content/TF_Lite-Models/tanh_act_int8.tflite\n",
            "Input size: 720.00B\n",
            "Output model: /content/Edge_TPU-Models/tanh_act_int8_edgetpu.tflite\n",
            "Output size: 20.59KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/tanh_act_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "TANH                           1          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/tanh_act_stacked3_int8.tflite\n",
            "Input size: 1016.00B\n",
            "Output model: /content/Edge_TPU-Models/tanh_act_stacked3_int8_edgetpu.tflite\n",
            "Output size: 24.59KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 3\n",
            "Operation log: /content/Edge_TPU-Models/tanh_act_stacked3_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "TANH                           3          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/tanh_act_stacked8_int8.tflite\n",
            "Input size: 1.76KiB\n",
            "Output model: /content/Edge_TPU-Models/tanh_act_stacked8_int8_edgetpu.tflite\n",
            "Output size: 24.59KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 8\n",
            "Operation log: /content/Edge_TPU-Models/tanh_act_stacked8_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "TANH                           8          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/sigmoid_act_int8.tflite\n",
            "Input size: 720.00B\n",
            "Output model: /content/Edge_TPU-Models/sigmoid_act_int8_edgetpu.tflite\n",
            "Output size: 20.59KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/sigmoid_act_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "LOGISTIC                       1          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/sigmoid_act_stacked3_int8.tflite\n",
            "Input size: 1.01KiB\n",
            "Output model: /content/Edge_TPU-Models/sigmoid_act_stacked3_int8_edgetpu.tflite\n",
            "Output size: 24.59KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 3\n",
            "Operation log: /content/Edge_TPU-Models/sigmoid_act_stacked3_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "LOGISTIC                       3          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/sigmoid_act_stacked8_int8.tflite\n",
            "Input size: 1.77KiB\n",
            "Output model: /content/Edge_TPU-Models/sigmoid_act_stacked8_int8_edgetpu.tflite\n",
            "Output size: 24.59KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 8\n",
            "Operation log: /content/Edge_TPU-Models/sigmoid_act_stacked8_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "LOGISTIC                       8          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/scalar_mult_int8.tflite\n",
            "Input size: 848.00B\n",
            "Output model: /content/Edge_TPU-Models/scalar_mult_int8_edgetpu.tflite\n",
            "Output size: 20.59KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/scalar_mult_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "MUL                            1          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/scalar_mult_stacked3_int8.tflite\n",
            "Input size: 1.16KiB\n",
            "Output model: /content/Edge_TPU-Models/scalar_mult_stacked3_int8_edgetpu.tflite\n",
            "Output size: 20.59KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 3\n",
            "Operation log: /content/Edge_TPU-Models/scalar_mult_stacked3_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "MUL                            3          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/scalar_mult_stacked8_int8.tflite\n",
            "Input size: 1.96KiB\n",
            "Output model: /content/Edge_TPU-Models/scalar_mult_stacked8_int8_edgetpu.tflite\n",
            "Output size: 24.59KiB\n",
            "On-chip memory used for caching model parameters: 0.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 8\n",
            "Operation log: /content/Edge_TPU-Models/scalar_mult_stacked8_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "MUL                            8          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/small_dense_int8.tflite\n",
            "Input size: 1.84KiB\n",
            "Output model: /content/Edge_TPU-Models/small_dense_int8_edgetpu.tflite\n",
            "Output size: 32.59KiB\n",
            "On-chip memory used for caching model parameters: 8.00KiB\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/small_dense_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "FULLY_CONNECTED                1          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/small_dense_stacked3_int8.tflite\n",
            "Input size: 2.60KiB\n",
            "Output model: /content/Edge_TPU-Models/small_dense_stacked3_int8_edgetpu.tflite\n",
            "Output size: 36.59KiB\n",
            "On-chip memory used for caching model parameters: 9.00KiB\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 3\n",
            "Operation log: /content/Edge_TPU-Models/small_dense_stacked3_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "FULLY_CONNECTED                3          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/small_dense_stacked8_int8.tflite\n",
            "Input size: 4.55KiB\n",
            "Output model: /content/Edge_TPU-Models/small_dense_stacked8_int8_edgetpu.tflite\n",
            "Output size: 44.59KiB\n",
            "On-chip memory used for caching model parameters: 11.50KiB\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 8\n",
            "Operation log: /content/Edge_TPU-Models/small_dense_stacked8_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "FULLY_CONNECTED                8          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/big_dense_int8.tflite\n",
            "Input size: 64.84KiB\n",
            "Output model: /content/Edge_TPU-Models/big_dense_int8_edgetpu.tflite\n",
            "Output size: 100.62KiB\n",
            "On-chip memory used for caching model parameters: 64.00KiB\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/big_dense_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "FULLY_CONNECTED                1          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/big_dense_stacked3_int8.tflite\n",
            "Input size: 577.48KiB\n",
            "Output model: /content/Edge_TPU-Models/big_dense_stacked3_int8_edgetpu.tflite\n",
            "Output size: 616.62KiB\n",
            "On-chip memory used for caching model parameters: 576.00KiB\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 3\n",
            "Operation log: /content/Edge_TPU-Models/big_dense_stacked3_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "FULLY_CONNECTED                3          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/big_dense_stacked8_int8.tflite\n",
            "Input size: 1.82MiB\n",
            "Output model: /content/Edge_TPU-Models/big_dense_stacked8_int8_edgetpu.tflite\n",
            "Output size: 1.87MiB\n",
            "On-chip memory used for caching model parameters: 832.00KiB\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 1.00MiB\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 8\n",
            "Operation log: /content/Edge_TPU-Models/big_dense_stacked8_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "FULLY_CONNECTED                8          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/simple_conv2d_int8.tflite\n",
            "Input size: 1.66KiB\n",
            "Output model: /content/Edge_TPU-Models/simple_conv2d_int8_edgetpu.tflite\n",
            "Output size: 60.62KiB\n",
            "On-chip memory used for caching model parameters: 2.75KiB\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/simple_conv2d_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        1          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/simple_conv2d_stacked3_int8.tflite\n",
            "Input size: 6.00KiB\n",
            "Output model: /content/Edge_TPU-Models/simple_conv2d_stacked3_int8_edgetpu.tflite\n",
            "Output size: 76.62KiB\n",
            "On-chip memory used for caching model parameters: 7.25KiB\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 2.50KiB\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 3\n",
            "Operation log: /content/Edge_TPU-Models/simple_conv2d_stacked3_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        3          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/simple_conv2d_stacked8_int8.tflite\n",
            "Input size: 16.72KiB\n",
            "Output model: /content/Edge_TPU-Models/simple_conv2d_stacked8_int8_edgetpu.tflite\n",
            "Output size: 120.62KiB\n",
            "On-chip memory used for caching model parameters: 7.25KiB\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 11.56KiB\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 8\n",
            "Operation log: /content/Edge_TPU-Models/simple_conv2d_stacked8_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        8          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/dilated_conv2d_int8.tflite\n",
            "Input size: 1.69KiB\n",
            "Output model: /content/Edge_TPU-Models/dilated_conv2d_int8_edgetpu.tflite\n",
            "Output size: 56.62KiB\n",
            "On-chip memory used for caching model parameters: 2.75KiB\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/dilated_conv2d_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        1          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/dilated_conv2d_stacked3_int8.tflite\n",
            "Input size: 6.03KiB\n",
            "Output model: /content/Edge_TPU-Models/dilated_conv2d_stacked3_int8_edgetpu.tflite\n",
            "Output size: 80.62KiB\n",
            "On-chip memory used for caching model parameters: 7.25KiB\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 2.50KiB\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 3\n",
            "Operation log: /content/Edge_TPU-Models/dilated_conv2d_stacked3_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        3          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/dilated_conv2d_stacked8_int8.tflite\n",
            "Input size: 16.83KiB\n",
            "Output model: /content/Edge_TPU-Models/dilated_conv2d_stacked8_int8_edgetpu.tflite\n",
            "Output size: 132.62KiB\n",
            "On-chip memory used for caching model parameters: 7.25KiB\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 11.56KiB\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 8\n",
            "Operation log: /content/Edge_TPU-Models/dilated_conv2d_stacked8_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        8          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/strided_conv2d_int8.tflite\n",
            "Input size: 1.67KiB\n",
            "Output model: /content/Edge_TPU-Models/strided_conv2d_int8_edgetpu.tflite\n",
            "Output size: 48.62KiB\n",
            "On-chip memory used for caching model parameters: 2.75KiB\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/strided_conv2d_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        1          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/strided_conv2d_stacked3_int8.tflite\n",
            "Input size: 6.02KiB\n",
            "Output model: /content/Edge_TPU-Models/strided_conv2d_stacked3_int8_edgetpu.tflite\n",
            "Output size: 56.62KiB\n",
            "On-chip memory used for caching model parameters: 10.00KiB\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 1.81KiB\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 3\n",
            "Operation log: /content/Edge_TPU-Models/strided_conv2d_stacked3_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        3          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/big_conv2d_int8.tflite\n",
            "Input size: 2.55KiB\n",
            "Output model: /content/Edge_TPU-Models/big_conv2d_int8_edgetpu.tflite\n",
            "Output size: 60.62KiB\n",
            "On-chip memory used for caching model parameters: 12.75KiB\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/big_conv2d_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        1          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/big_conv2d_stacked3_int8.tflite\n",
            "Input size: 11.92KiB\n",
            "Output model: /content/Edge_TPU-Models/big_conv2d_stacked3_int8_edgetpu.tflite\n",
            "Output size: 96.62KiB\n",
            "On-chip memory used for caching model parameters: 74.50KiB\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 3.19KiB\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 3\n",
            "Operation log: /content/Edge_TPU-Models/big_conv2d_stacked3_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        3          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/big_conv2d_stacked8_int8.tflite\n",
            "Input size: 35.22KiB\n",
            "Output model: /content/Edge_TPU-Models/big_conv2d_stacked8_int8_edgetpu.tflite\n",
            "Output size: 188.62KiB\n",
            "On-chip memory used for caching model parameters: 111.75KiB\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 40.44KiB\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 8\n",
            "Operation log: /content/Edge_TPU-Models/big_conv2d_stacked8_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        8          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/small_conv2d_int8.tflite\n",
            "Input size: 1.51KiB\n",
            "Output model: /content/Edge_TPU-Models/small_conv2d_int8_edgetpu.tflite\n",
            "Output size: 60.62KiB\n",
            "On-chip memory used for caching model parameters: 2.75KiB\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/small_conv2d_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        1          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/small_conv2d_stacked3_int8.tflite\n",
            "Input size: 4.58KiB\n",
            "Output model: /content/Edge_TPU-Models/small_conv2d_stacked3_int8_edgetpu.tflite\n",
            "Output size: 76.62KiB\n",
            "On-chip memory used for caching model parameters: 7.25KiB\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 2.50KiB\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 3\n",
            "Operation log: /content/Edge_TPU-Models/small_conv2d_stacked3_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        3          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/small_conv2d_stacked8_int8.tflite\n",
            "Input size: 12.13KiB\n",
            "Output model: /content/Edge_TPU-Models/small_conv2d_stacked8_int8_edgetpu.tflite\n",
            "Output size: 120.62KiB\n",
            "On-chip memory used for caching model parameters: 7.25KiB\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 11.56KiB\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 8\n",
            "Operation log: /content/Edge_TPU-Models/small_conv2d_stacked8_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        8          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/many_conv2d_int8.tflite\n",
            "Input size: 14.77KiB\n",
            "Output model: /content/Edge_TPU-Models/many_conv2d_int8_edgetpu.tflite\n",
            "Output size: 72.62KiB\n",
            "On-chip memory used for caching model parameters: 11.00KiB\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/many_conv2d_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        1          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/many_conv2d_stacked3_int8.tflite\n",
            "Input size: 1.15MiB\n",
            "Output model: /content/Edge_TPU-Models/many_conv2d_stacked3_int8_edgetpu.tflite\n",
            "Output size: 1.33MiB\n",
            "On-chip memory used for caching model parameters: 1.14MiB\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 3\n",
            "Operation log: /content/Edge_TPU-Models/many_conv2d_stacked3_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        3          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/many_conv2d_stacked8_int8.tflite\n",
            "Input size: 4.00MiB\n",
            "Output model: /content/Edge_TPU-Models/many_conv2d_stacked8_int8_edgetpu.tflite\n",
            "Output size: 4.38MiB\n",
            "On-chip memory used for caching model parameters: 3.96MiB\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 8\n",
            "Operation log: /content/Edge_TPU-Models/many_conv2d_stacked8_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        8          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/few_conv2d_int8.tflite\n",
            "Input size: 1.18KiB\n",
            "Output model: /content/Edge_TPU-Models/few_conv2d_int8_edgetpu.tflite\n",
            "Output size: 56.62KiB\n",
            "On-chip memory used for caching model parameters: 256.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 1\n",
            "Operation log: /content/Edge_TPU-Models/few_conv2d_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        1          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/few_conv2d_stacked3_int8.tflite\n",
            "Input size: 2.62KiB\n",
            "Output model: /content/Edge_TPU-Models/few_conv2d_stacked3_int8_edgetpu.tflite\n",
            "Output size: 72.62KiB\n",
            "On-chip memory used for caching model parameters: 512.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 704.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 3\n",
            "Operation log: /content/Edge_TPU-Models/few_conv2d_stacked3_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        3          Mapped to Edge TPU\n",
            "\n",
            "Input model: /content/TF_Lite-Models/few_conv2d_stacked8_int8.tflite\n",
            "Input size: 6.12KiB\n",
            "Output model: /content/Edge_TPU-Models/few_conv2d_stacked8_int8_edgetpu.tflite\n",
            "Output size: 112.62KiB\n",
            "On-chip memory used for caching model parameters: 256.00B\n",
            "On-chip memory remaining for caching model parameters: 0.00B\n",
            "Off-chip memory used for streaming uncached model parameters: 4.81KiB\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 8\n",
            "Operation log: /content/Edge_TPU-Models/few_conv2d_stacked8_int8_edgetpu.log\n",
            "\n",
            "Operator                       Count      Status\n",
            "\n",
            "CONV_2D                        8          Mapped to Edge TPU\n",
            "Compilation child process completed within timeout period.\n",
            "Compilation succeeded! \n",
            "\n"
          ]
        }
      ],
      "source": [
        "if not os.path.isdir(\"Edge_TPU-Models\"): os.mkdir(\"Edge_TPU-Models\")\n",
        "\n",
        "filenames = \"\"\n",
        "for model in models:\n",
        "  filenames += \" \"+current_dir+\"/TF_Lite-Models/\"+model.name+\"_int8.tflite\"\n",
        "result = subprocess.run(['edgetpu_compiler','-s','-o',\n",
        "                         current_dir+'/Edge_TPU-Models',*filenames.split()],\n",
        "                        stdout=subprocess.PIPE)\n",
        "print(result.stdout.decode('ascii'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Kopie von ai_hardware_accelerators_colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}